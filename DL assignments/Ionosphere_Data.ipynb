{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ionosphere Data.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qm6SVEktF6Pb"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from keras import models\n",
        "from keras import layers\n",
        "from keras import regularizers"
      ],
      "execution_count": 298,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "x04KH4qVJLVH",
        "outputId": "cd2d29d4-2a3e-4baa-dc9a-933df9918a26"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 405,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-46d96a26-63fa-4c4f-acad-bff4d98197c5\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-46d96a26-63fa-4c4f-acad-bff4d98197c5\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving ionosphere_data.csv to ionosphere_data (3).csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KyuugC0gJffo"
      },
      "source": [
        "import io\n",
        "df = pd.read_csv(io.BytesIO(uploaded[\"ionosphere_data.csv\"]))"
      ],
      "execution_count": 406,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dy_Ftds7J-Xo"
      },
      "source": [
        "**Verifying the Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nWnk-coqKuCA",
        "outputId": "9ca7f8b6-3244-4216-a137-bdc1497ea3c5"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": 407,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 351 entries, 0 to 350\n",
            "Data columns (total 35 columns):\n",
            " #   Column     Non-Null Count  Dtype  \n",
            "---  ------     --------------  -----  \n",
            " 0   feature1   351 non-null    int64  \n",
            " 1   feature2   351 non-null    int64  \n",
            " 2   feature3   351 non-null    float64\n",
            " 3   feature4   351 non-null    float64\n",
            " 4   feature5   351 non-null    float64\n",
            " 5   feature6   351 non-null    float64\n",
            " 6   feature7   351 non-null    float64\n",
            " 7   feature8   351 non-null    float64\n",
            " 8   feature9   351 non-null    float64\n",
            " 9   feature10  351 non-null    float64\n",
            " 10  feature11  351 non-null    float64\n",
            " 11  feature12  351 non-null    float64\n",
            " 12  feature13  351 non-null    float64\n",
            " 13  feature14  351 non-null    float64\n",
            " 14  feature15  351 non-null    float64\n",
            " 15  feature16  351 non-null    float64\n",
            " 16  feature17  351 non-null    float64\n",
            " 17  feature18  351 non-null    float64\n",
            " 18  feature19  351 non-null    float64\n",
            " 19  feature20  351 non-null    float64\n",
            " 20  feature21  351 non-null    float64\n",
            " 21  feature22  351 non-null    float64\n",
            " 22  feature23  351 non-null    float64\n",
            " 23  feature24  351 non-null    float64\n",
            " 24  feature25  351 non-null    float64\n",
            " 25  feature26  351 non-null    float64\n",
            " 26  feature27  351 non-null    float64\n",
            " 27  feature28  351 non-null    float64\n",
            " 28  feature29  351 non-null    float64\n",
            " 29  feature30  351 non-null    float64\n",
            " 30  feature31  351 non-null    float64\n",
            " 31  feature32  351 non-null    float64\n",
            " 32  feature33  351 non-null    float64\n",
            " 33  feature34  351 non-null    float64\n",
            " 34  label      351 non-null    object \n",
            "dtypes: float64(32), int64(2), object(1)\n",
            "memory usage: 96.1+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qtK1XYtQKxaq",
        "outputId": "3354084d-c397-4944-f2ac-9d269bb031ef"
      },
      "source": [
        "normalized_data=df.copy()\n",
        "normalized_data.shape"
      ],
      "execution_count": 408,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(351, 35)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 408
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        },
        "id": "ytipkCAfQK3m",
        "outputId": "96a408e2-c615-4c84-d20e-5cbd010efd88"
      },
      "source": [
        "normalized_data[normalized_data.duplicated()]"
      ],
      "execution_count": 409,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature1</th>\n",
              "      <th>feature2</th>\n",
              "      <th>feature3</th>\n",
              "      <th>feature4</th>\n",
              "      <th>feature5</th>\n",
              "      <th>feature6</th>\n",
              "      <th>feature7</th>\n",
              "      <th>feature8</th>\n",
              "      <th>feature9</th>\n",
              "      <th>feature10</th>\n",
              "      <th>feature11</th>\n",
              "      <th>feature12</th>\n",
              "      <th>feature13</th>\n",
              "      <th>feature14</th>\n",
              "      <th>feature15</th>\n",
              "      <th>feature16</th>\n",
              "      <th>feature17</th>\n",
              "      <th>feature18</th>\n",
              "      <th>feature19</th>\n",
              "      <th>feature20</th>\n",
              "      <th>feature21</th>\n",
              "      <th>feature22</th>\n",
              "      <th>feature23</th>\n",
              "      <th>feature24</th>\n",
              "      <th>feature25</th>\n",
              "      <th>feature26</th>\n",
              "      <th>feature27</th>\n",
              "      <th>feature28</th>\n",
              "      <th>feature29</th>\n",
              "      <th>feature30</th>\n",
              "      <th>feature31</th>\n",
              "      <th>feature32</th>\n",
              "      <th>feature33</th>\n",
              "      <th>feature34</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>248</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>b</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     feature1  feature2  feature3  ...  feature33  feature34  label\n",
              "248         0         0       0.0  ...        0.0        0.0      b\n",
              "\n",
              "[1 rows x 35 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 409
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s26mbHH-LCCd",
        "outputId": "8f835660-5981-4d3c-afeb-2e7fd42b0e64"
      },
      "source": [
        "normalized_data.drop_duplicates(inplace = True)\n",
        "normalized_data.shape"
      ],
      "execution_count": 410,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(350, 35)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 410
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_2T0APoeLv0T",
        "outputId": "98aacb28-55e3-42ff-cb65-fdbd40468802"
      },
      "source": [
        "normalized_data[\"feature2\"].value_counts()"
      ],
      "execution_count": 411,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    350\n",
              "Name: feature2, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 411
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97UzPj0zMlrS",
        "outputId": "63b7c38b-d643-4753-fe15-1163dbeefb0f"
      },
      "source": [
        "normalized_data.drop(columns=[\"feature2\"], inplace = True)\n",
        "normalized_data.shape"
      ],
      "execution_count": 412,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(350, 34)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 412
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uoWeCl7hPiQo",
        "outputId": "c364b45f-6a2b-4d59-e2b3-83628182f699"
      },
      "source": [
        "data = normalized_data # sample(normalized_data.shape[0], random_state=1)\n",
        "data.shape"
      ],
      "execution_count": 413,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(350, 34)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 413
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dd1O86b6Zoa-"
      },
      "source": [
        "class_g = data[data[\"label\"]==\"g\"]\n",
        "class_b = data[data[\"label\"]==\"b\"]"
      ],
      "execution_count": 414,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oO4aF2sMZpS2",
        "outputId": "2ea9436f-887a-47a9-f222-2e12f7faf6c9"
      },
      "source": [
        "class_g.shape"
      ],
      "execution_count": 415,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(225, 34)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 415
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zR-vBM32Zpke",
        "outputId": "80b001b8-7eac-49c9-98b9-ce5df9fa44b7"
      },
      "source": [
        "class_b.shape"
      ],
      "execution_count": 416,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(125, 34)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 416
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kp6RO2xNYel9"
      },
      "source": [
        "data_over = pd.concat([class_b, class_g], axis=0)"
      ],
      "execution_count": 418,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ge4xbup4Zpwv",
        "outputId": "9aa65a9f-ae0f-447d-d666-ec53c2e65767"
      },
      "source": [
        "data_over[\"label\"].value_counts()"
      ],
      "execution_count": 419,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "g    225\n",
              "b    125\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 419
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FpLJr7K_eM6r",
        "outputId": "6501d6ff-a149-4073-837f-0d8fea169adf"
      },
      "source": [
        "len(data_over)"
      ],
      "execution_count": 420,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "350"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 420
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zwcdl1ZSQuy3"
      },
      "source": [
        "**Splitting the Traing and Testing data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DxwUy3F-LjI_"
      },
      "source": [
        "x_data = data_over.sample(frac=1) # Shuffling the data\n",
        "train_data_full= x_data.iloc[:210,:]\n",
        "test_data_full = x_data.iloc[210:, :]\n",
        "train_data = train_data_full.iloc[:, :-1]\n",
        "train_labels = train_data_full.iloc[:, -1]\n",
        "test_data = test_data_full.iloc[:, :-1]\n",
        "test_labels = test_data_full.iloc[:, -1]"
      ],
      "execution_count": 421,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WqFw1Ql8Lj9S",
        "outputId": "cd88a051-8158-422d-afa5-2b9b088ae201"
      },
      "source": [
        "print(train_data.shape)\n",
        "print(test_data.shape)\n",
        "print(train_labels.shape)\n",
        "print(test_labels.shape)"
      ],
      "execution_count": 422,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(210, 33)\n",
            "(140, 33)\n",
            "(210,)\n",
            "(140,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VN9atXO9RiIR",
        "outputId": "809c39a3-7e16-44e2-88bc-1830af270ed6"
      },
      "source": [
        "train_data.shape, test_data.shape"
      ],
      "execution_count": 423,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((210, 33), (140, 33))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 423
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1pWm6bhupHZB",
        "outputId": "027c554e-9eb3-46b5-b101-62b2c4aa752a"
      },
      "source": [
        "train_labels.shape, test_labels.shape"
      ],
      "execution_count": 424,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((210,), (140,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 424
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A1566qUbSi4T"
      },
      "source": [
        "**Normalizing the data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVKYVDaobtW-"
      },
      "source": [
        "mean = train_data.mean(axis=0)\n",
        "train_data -=mean\n",
        "std =train_data.std(axis=0)\n",
        "train_data /=std\n",
        "\n",
        "test_data -=mean\n",
        "test_data /=std"
      ],
      "execution_count": 425,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6BVeq4--TGHe"
      },
      "source": [
        "train_labels = np.where(train_labels ==\"g\", 1, 0 )\n",
        "test_labels = np.where(test_labels ==\"g\",1,0)\n",
        "\n",
        "train_labels=np.asarray(train_labels).astype(dtype=\"float64\")\n",
        "test_labels=np.asarray(test_labels).astype(dtype=\"float64\")"
      ],
      "execution_count": 426,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "596dVSIih8P2"
      },
      "source": [
        "**Building the Network**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VlqdGtmKhmq3"
      },
      "source": [
        "def build_model():\n",
        "  model=models.Sequential()\n",
        "  model.add(layers.Dense(16,kernel_regularizer=regularizers.l1_l2(l1=.002, l2=0.004) , activation=\"relu\", input_shape=(train_data.shape[1],)))\n",
        "  model.add(layers.Dropout(.5))\n",
        "  model.add(layers.Dense(16, kernel_regularizer=regularizers.l1_l2(l1=.002, l2=0.004), activation = \"relu\" ))\n",
        "  model.add(layers.Dropout(.3))\n",
        "  model.add(layers.Dense(1, activation=\"sigmoid\"))\n",
        "\n",
        "  model.compile(optimizer=\"rmsprop\", loss = \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "  return model"
      ],
      "execution_count": 427,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qowYHYALiPOB"
      },
      "source": [
        "**K fold Validation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b7llzdZyiFEL",
        "outputId": "0fa19618-90ed-47e5-d94e-26fb531efa6c"
      },
      "source": [
        "k= 5\n",
        "num_val_sample = len(train_data) // k\n",
        "num_epochs =90\n",
        "all_scores = []\n",
        "all_val_loss_histories = []\n",
        "all_val_acc_histories = []\n",
        "all_loss_histories =[]\n",
        "all_acc_histories = []\n",
        "\n",
        "for i in range(k):\n",
        "  print(\"processing fold #\",i)\n",
        "  val_data = train_data[i*num_val_sample:(i+1)*num_val_sample]\n",
        "  val_labels = train_labels[i*num_val_sample: (i+1)*num_val_sample]\n",
        "\n",
        "  partial_train_data=np.concatenate([train_data[:i*num_val_sample], train_data[(i+1)*num_val_sample:]], axis=0)\n",
        "  partial_train_labels=np.concatenate([train_labels[:i*num_val_sample], train_labels[(i+1)*num_val_sample:]], axis=0)\n",
        "\n",
        "  model=build_model()\n",
        "  history = model.fit(partial_train_data, partial_train_labels, validation_data = (val_data, val_labels), batch_size=4, epochs= num_epochs, verbose=1)\n",
        "  val_loss, val_acc = model.evaluate(test_data, test_labels, verbose=0)\n",
        "  val_loss_history = history.history[\"val_loss\"]\n",
        "  val_acc_history = history.history[\"val_accuracy\"]\n",
        "  loss_history = history.history[\"loss\"]\n",
        "  acc_history = history.history[\"accuracy\"]\n",
        "  all_loss_histories.append(loss_history)\n",
        "  all_acc_histories.append(acc_history)\n",
        "  all_val_loss_histories.append(val_loss_history)\n",
        "  all_val_acc_histories.append(val_acc_history)\n",
        "  all_scores.append(val_acc)\n",
        "ave_val_loss_hist = [np.mean([x[i] for x in all_val_loss_histories]) for i in range(num_epochs)]\n",
        "ave_loss_hist = [np.mean([x[i] for x in all_loss_histories]) for i in range(num_epochs)]\n",
        "ave_val_acc_hist = [np.mean([x[i] for x in all_val_acc_histories]) for i in range(num_epochs)]\n",
        "ave_acc_hist = [np.mean([x[i] for x in all_acc_histories]) for i in range(num_epochs)]\n",
        "all_scores\n"
      ],
      "execution_count": 428,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "processing fold # 0\n",
            "Epoch 1/90\n",
            "42/42 [==============================] - 1s 8ms/step - loss: 1.3160 - accuracy: 0.4708 - val_loss: 1.1028 - val_accuracy: 0.6905\n",
            "Epoch 2/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 1.1267 - accuracy: 0.5336 - val_loss: 1.0457 - val_accuracy: 0.7381\n",
            "Epoch 3/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 1.0396 - accuracy: 0.6904 - val_loss: 0.9969 - val_accuracy: 0.7619\n",
            "Epoch 4/90\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 1.0155 - accuracy: 0.7238 - val_loss: 0.9511 - val_accuracy: 0.7619\n",
            "Epoch 5/90\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 1.0528 - accuracy: 0.6421 - val_loss: 0.9118 - val_accuracy: 0.7857\n",
            "Epoch 6/90\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.9692 - accuracy: 0.7749 - val_loss: 0.8885 - val_accuracy: 0.7857\n",
            "Epoch 7/90\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.9434 - accuracy: 0.7115 - val_loss: 0.8603 - val_accuracy: 0.7857\n",
            "Epoch 8/90\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.8258 - accuracy: 0.8598 - val_loss: 0.8332 - val_accuracy: 0.8095\n",
            "Epoch 9/90\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.9370 - accuracy: 0.7212 - val_loss: 0.8127 - val_accuracy: 0.8333\n",
            "Epoch 10/90\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.8743 - accuracy: 0.8071 - val_loss: 0.7900 - val_accuracy: 0.8333\n",
            "Epoch 11/90\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.9470 - accuracy: 0.6795 - val_loss: 0.7805 - val_accuracy: 0.8571\n",
            "Epoch 12/90\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.7653 - accuracy: 0.8505 - val_loss: 0.7600 - val_accuracy: 0.8571\n",
            "Epoch 13/90\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.8046 - accuracy: 0.7798 - val_loss: 0.7443 - val_accuracy: 0.8571\n",
            "Epoch 14/90\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.8095 - accuracy: 0.8012 - val_loss: 0.7363 - val_accuracy: 0.8333\n",
            "Epoch 15/90\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.7798 - accuracy: 0.7771 - val_loss: 0.7295 - val_accuracy: 0.8333\n",
            "Epoch 16/90\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.7155 - accuracy: 0.8189 - val_loss: 0.7119 - val_accuracy: 0.8571\n",
            "Epoch 17/90\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.6865 - accuracy: 0.8502 - val_loss: 0.7032 - val_accuracy: 0.8571\n",
            "Epoch 18/90\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.6810 - accuracy: 0.8461 - val_loss: 0.6990 - val_accuracy: 0.8333\n",
            "Epoch 19/90\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.6662 - accuracy: 0.8693 - val_loss: 0.6994 - val_accuracy: 0.8095\n",
            "Epoch 20/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.6568 - accuracy: 0.8767 - val_loss: 0.6757 - val_accuracy: 0.8333\n",
            "Epoch 21/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.5925 - accuracy: 0.9124 - val_loss: 0.6635 - val_accuracy: 0.8333\n",
            "Epoch 22/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.6208 - accuracy: 0.8615 - val_loss: 0.6537 - val_accuracy: 0.8333\n",
            "Epoch 23/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.5835 - accuracy: 0.8773 - val_loss: 0.6524 - val_accuracy: 0.7857\n",
            "Epoch 24/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.5933 - accuracy: 0.8610 - val_loss: 0.6417 - val_accuracy: 0.7857\n",
            "Epoch 25/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.5712 - accuracy: 0.8956 - val_loss: 0.6436 - val_accuracy: 0.7857\n",
            "Epoch 26/90\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.5565 - accuracy: 0.8945 - val_loss: 0.6473 - val_accuracy: 0.8095\n",
            "Epoch 27/90\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.5646 - accuracy: 0.8711 - val_loss: 0.6366 - val_accuracy: 0.8095\n",
            "Epoch 28/90\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.5178 - accuracy: 0.8801 - val_loss: 0.6201 - val_accuracy: 0.8333\n",
            "Epoch 29/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.5166 - accuracy: 0.9165 - val_loss: 0.6167 - val_accuracy: 0.8333\n",
            "Epoch 30/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.5194 - accuracy: 0.8354 - val_loss: 0.6148 - val_accuracy: 0.8333\n",
            "Epoch 31/90\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.5299 - accuracy: 0.8153 - val_loss: 0.6012 - val_accuracy: 0.8095\n",
            "Epoch 32/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.4782 - accuracy: 0.8923 - val_loss: 0.5951 - val_accuracy: 0.8095\n",
            "Epoch 33/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.5450 - accuracy: 0.8790 - val_loss: 0.6018 - val_accuracy: 0.8095\n",
            "Epoch 34/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.5171 - accuracy: 0.8746 - val_loss: 0.6014 - val_accuracy: 0.8095\n",
            "Epoch 35/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.4919 - accuracy: 0.9243 - val_loss: 0.5856 - val_accuracy: 0.8333\n",
            "Epoch 36/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.4580 - accuracy: 0.9137 - val_loss: 0.5794 - val_accuracy: 0.8333\n",
            "Epoch 37/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.4138 - accuracy: 0.9162 - val_loss: 0.5813 - val_accuracy: 0.8333\n",
            "Epoch 38/90\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.4617 - accuracy: 0.8992 - val_loss: 0.5714 - val_accuracy: 0.8333\n",
            "Epoch 39/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.4314 - accuracy: 0.9083 - val_loss: 0.5651 - val_accuracy: 0.8333\n",
            "Epoch 40/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.4464 - accuracy: 0.9014 - val_loss: 0.5743 - val_accuracy: 0.8333\n",
            "Epoch 41/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.4365 - accuracy: 0.8943 - val_loss: 0.5681 - val_accuracy: 0.8333\n",
            "Epoch 42/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.4427 - accuracy: 0.8955 - val_loss: 0.5660 - val_accuracy: 0.8333\n",
            "Epoch 43/90\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.4519 - accuracy: 0.8740 - val_loss: 0.5509 - val_accuracy: 0.8333\n",
            "Epoch 44/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.4748 - accuracy: 0.8561 - val_loss: 0.5270 - val_accuracy: 0.8333\n",
            "Epoch 45/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.4692 - accuracy: 0.8629 - val_loss: 0.5325 - val_accuracy: 0.8333\n",
            "Epoch 46/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.3633 - accuracy: 0.9207 - val_loss: 0.5394 - val_accuracy: 0.8333\n",
            "Epoch 47/90\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.4077 - accuracy: 0.9221 - val_loss: 0.5262 - val_accuracy: 0.8571\n",
            "Epoch 48/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.4438 - accuracy: 0.8577 - val_loss: 0.5133 - val_accuracy: 0.8333\n",
            "Epoch 49/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.3815 - accuracy: 0.9336 - val_loss: 0.5116 - val_accuracy: 0.8333\n",
            "Epoch 50/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.4512 - accuracy: 0.8687 - val_loss: 0.4906 - val_accuracy: 0.8571\n",
            "Epoch 51/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.3713 - accuracy: 0.9010 - val_loss: 0.4800 - val_accuracy: 0.8571\n",
            "Epoch 52/90\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.4106 - accuracy: 0.9150 - val_loss: 0.4749 - val_accuracy: 0.8571\n",
            "Epoch 53/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.4150 - accuracy: 0.9097 - val_loss: 0.4775 - val_accuracy: 0.8571\n",
            "Epoch 54/90\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.3756 - accuracy: 0.9272 - val_loss: 0.4859 - val_accuracy: 0.8571\n",
            "Epoch 55/90\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.3866 - accuracy: 0.9263 - val_loss: 0.4914 - val_accuracy: 0.8571\n",
            "Epoch 56/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.3563 - accuracy: 0.9220 - val_loss: 0.4920 - val_accuracy: 0.8571\n",
            "Epoch 57/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.3872 - accuracy: 0.9113 - val_loss: 0.4687 - val_accuracy: 0.8571\n",
            "Epoch 58/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.4308 - accuracy: 0.8940 - val_loss: 0.4768 - val_accuracy: 0.8571\n",
            "Epoch 59/90\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.3954 - accuracy: 0.9400 - val_loss: 0.4662 - val_accuracy: 0.8571\n",
            "Epoch 60/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.3673 - accuracy: 0.9162 - val_loss: 0.4606 - val_accuracy: 0.8571\n",
            "Epoch 61/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.3753 - accuracy: 0.9132 - val_loss: 0.4552 - val_accuracy: 0.8571\n",
            "Epoch 62/90\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.3836 - accuracy: 0.8954 - val_loss: 0.4505 - val_accuracy: 0.8571\n",
            "Epoch 63/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.3404 - accuracy: 0.9319 - val_loss: 0.4489 - val_accuracy: 0.8571\n",
            "Epoch 64/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.4573 - accuracy: 0.8632 - val_loss: 0.4450 - val_accuracy: 0.8571\n",
            "Epoch 65/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.4317 - accuracy: 0.8844 - val_loss: 0.4526 - val_accuracy: 0.8571\n",
            "Epoch 66/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.3957 - accuracy: 0.8733 - val_loss: 0.4424 - val_accuracy: 0.8571\n",
            "Epoch 67/90\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.3949 - accuracy: 0.9250 - val_loss: 0.4530 - val_accuracy: 0.8571\n",
            "Epoch 68/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.2944 - accuracy: 0.9538 - val_loss: 0.4391 - val_accuracy: 0.8810\n",
            "Epoch 69/90\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.4325 - accuracy: 0.8503 - val_loss: 0.4350 - val_accuracy: 0.8810\n",
            "Epoch 70/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.3561 - accuracy: 0.8973 - val_loss: 0.4314 - val_accuracy: 0.8810\n",
            "Epoch 71/90\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.4073 - accuracy: 0.8510 - val_loss: 0.4362 - val_accuracy: 0.8571\n",
            "Epoch 72/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.4226 - accuracy: 0.8997 - val_loss: 0.4475 - val_accuracy: 0.8571\n",
            "Epoch 73/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.3856 - accuracy: 0.8984 - val_loss: 0.4465 - val_accuracy: 0.8571\n",
            "Epoch 74/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.4207 - accuracy: 0.8939 - val_loss: 0.4270 - val_accuracy: 0.8571\n",
            "Epoch 75/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.3682 - accuracy: 0.9048 - val_loss: 0.4327 - val_accuracy: 0.8571\n",
            "Epoch 76/90\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.3813 - accuracy: 0.9105 - val_loss: 0.4070 - val_accuracy: 0.8571\n",
            "Epoch 77/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.3138 - accuracy: 0.9239 - val_loss: 0.4218 - val_accuracy: 0.8571\n",
            "Epoch 78/90\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.3388 - accuracy: 0.9218 - val_loss: 0.4243 - val_accuracy: 0.8571\n",
            "Epoch 79/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.4167 - accuracy: 0.8870 - val_loss: 0.4258 - val_accuracy: 0.8571\n",
            "Epoch 80/90\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.3308 - accuracy: 0.9140 - val_loss: 0.4293 - val_accuracy: 0.8571\n",
            "Epoch 81/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.3420 - accuracy: 0.9164 - val_loss: 0.4181 - val_accuracy: 0.8571\n",
            "Epoch 82/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.3416 - accuracy: 0.9320 - val_loss: 0.4010 - val_accuracy: 0.8571\n",
            "Epoch 83/90\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.3497 - accuracy: 0.9140 - val_loss: 0.4243 - val_accuracy: 0.8571\n",
            "Epoch 84/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.2889 - accuracy: 0.9419 - val_loss: 0.4027 - val_accuracy: 0.8571\n",
            "Epoch 85/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.3789 - accuracy: 0.9090 - val_loss: 0.4055 - val_accuracy: 0.8571\n",
            "Epoch 86/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.3041 - accuracy: 0.9204 - val_loss: 0.4159 - val_accuracy: 0.8571\n",
            "Epoch 87/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.3288 - accuracy: 0.9176 - val_loss: 0.3851 - val_accuracy: 0.8571\n",
            "Epoch 88/90\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.2816 - accuracy: 0.9374 - val_loss: 0.4064 - val_accuracy: 0.8571\n",
            "Epoch 89/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.4291 - accuracy: 0.8397 - val_loss: 0.3872 - val_accuracy: 0.8571\n",
            "Epoch 90/90\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.3361 - accuracy: 0.9243 - val_loss: 0.3919 - val_accuracy: 0.8571\n",
            "processing fold # 1\n",
            "Epoch 1/90\n",
            "42/42 [==============================] - 1s 7ms/step - loss: 1.2671 - accuracy: 0.5473 - val_loss: 0.9695 - val_accuracy: 0.7143\n",
            "Epoch 2/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 1.1366 - accuracy: 0.5642 - val_loss: 0.8963 - val_accuracy: 0.7857\n",
            "Epoch 3/90\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 1.0669 - accuracy: 0.7107 - val_loss: 0.8643 - val_accuracy: 0.8095\n",
            "Epoch 4/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.9623 - accuracy: 0.6548 - val_loss: 0.8530 - val_accuracy: 0.8095\n",
            "Epoch 5/90\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 1.0341 - accuracy: 0.7082 - val_loss: 0.8368 - val_accuracy: 0.8810\n",
            "Epoch 6/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.9192 - accuracy: 0.7562 - val_loss: 0.8202 - val_accuracy: 0.8571\n",
            "Epoch 7/90\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.9099 - accuracy: 0.7551 - val_loss: 0.8022 - val_accuracy: 0.8571\n",
            "Epoch 8/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.7732 - accuracy: 0.8685 - val_loss: 0.7803 - val_accuracy: 0.8571\n",
            "Epoch 9/90\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.8072 - accuracy: 0.8310 - val_loss: 0.7786 - val_accuracy: 0.8571\n",
            "Epoch 10/90\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.8952 - accuracy: 0.7685 - val_loss: 0.7625 - val_accuracy: 0.8571\n",
            "Epoch 11/90\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.7832 - accuracy: 0.8528 - val_loss: 0.7600 - val_accuracy: 0.8333\n",
            "Epoch 12/90\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.6724 - accuracy: 0.8756 - val_loss: 0.7500 - val_accuracy: 0.8333\n",
            "Epoch 13/90\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.6681 - accuracy: 0.8690 - val_loss: 0.7173 - val_accuracy: 0.8333\n",
            "Epoch 14/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.7396 - accuracy: 0.8087 - val_loss: 0.7116 - val_accuracy: 0.8333\n",
            "Epoch 15/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.6987 - accuracy: 0.8525 - val_loss: 0.6997 - val_accuracy: 0.8333\n",
            "Epoch 16/90\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.6525 - accuracy: 0.8538 - val_loss: 0.6852 - val_accuracy: 0.8571\n",
            "Epoch 17/90\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.6429 - accuracy: 0.9008 - val_loss: 0.6747 - val_accuracy: 0.8333\n",
            "Epoch 18/90\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.6964 - accuracy: 0.8724 - val_loss: 0.6794 - val_accuracy: 0.8333\n",
            "Epoch 19/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.6695 - accuracy: 0.8454 - val_loss: 0.6697 - val_accuracy: 0.8333\n",
            "Epoch 20/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.5426 - accuracy: 0.9170 - val_loss: 0.6593 - val_accuracy: 0.8333\n",
            "Epoch 21/90\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.5954 - accuracy: 0.9189 - val_loss: 0.6495 - val_accuracy: 0.8333\n",
            "Epoch 22/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.5336 - accuracy: 0.9000 - val_loss: 0.6386 - val_accuracy: 0.8571\n",
            "Epoch 23/90\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.5391 - accuracy: 0.8732 - val_loss: 0.6329 - val_accuracy: 0.8571\n",
            "Epoch 24/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.5409 - accuracy: 0.8556 - val_loss: 0.6291 - val_accuracy: 0.8571\n",
            "Epoch 25/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.5451 - accuracy: 0.8628 - val_loss: 0.6166 - val_accuracy: 0.8571\n",
            "Epoch 26/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.4892 - accuracy: 0.9104 - val_loss: 0.6113 - val_accuracy: 0.8571\n",
            "Epoch 27/90\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.4661 - accuracy: 0.8870 - val_loss: 0.5982 - val_accuracy: 0.8571\n",
            "Epoch 28/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.5166 - accuracy: 0.9204 - val_loss: 0.5663 - val_accuracy: 0.8571\n",
            "Epoch 29/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.4730 - accuracy: 0.9123 - val_loss: 0.5843 - val_accuracy: 0.8333\n",
            "Epoch 30/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.4609 - accuracy: 0.9090 - val_loss: 0.5701 - val_accuracy: 0.8571\n",
            "Epoch 31/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.4940 - accuracy: 0.8871 - val_loss: 0.5759 - val_accuracy: 0.8571\n",
            "Epoch 32/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.4745 - accuracy: 0.8725 - val_loss: 0.5674 - val_accuracy: 0.8571\n",
            "Epoch 33/90\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.4092 - accuracy: 0.9545 - val_loss: 0.5539 - val_accuracy: 0.8571\n",
            "Epoch 34/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.4062 - accuracy: 0.9394 - val_loss: 0.5625 - val_accuracy: 0.8571\n",
            "Epoch 35/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.4335 - accuracy: 0.9342 - val_loss: 0.5533 - val_accuracy: 0.8333\n",
            "Epoch 36/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.3630 - accuracy: 0.9478 - val_loss: 0.5507 - val_accuracy: 0.8333\n",
            "Epoch 37/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.4322 - accuracy: 0.8778 - val_loss: 0.5459 - val_accuracy: 0.8571\n",
            "Epoch 38/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.4257 - accuracy: 0.9110 - val_loss: 0.5476 - val_accuracy: 0.8333\n",
            "Epoch 39/90\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.4601 - accuracy: 0.8756 - val_loss: 0.5407 - val_accuracy: 0.8571\n",
            "Epoch 40/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.3996 - accuracy: 0.9414 - val_loss: 0.5150 - val_accuracy: 0.8571\n",
            "Epoch 41/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.4111 - accuracy: 0.9278 - val_loss: 0.5065 - val_accuracy: 0.8571\n",
            "Epoch 42/90\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.3853 - accuracy: 0.9378 - val_loss: 0.4962 - val_accuracy: 0.8571\n",
            "Epoch 43/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.3785 - accuracy: 0.9393 - val_loss: 0.5110 - val_accuracy: 0.8571\n",
            "Epoch 44/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.3581 - accuracy: 0.9454 - val_loss: 0.5228 - val_accuracy: 0.8333\n",
            "Epoch 45/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.4406 - accuracy: 0.9348 - val_loss: 0.5109 - val_accuracy: 0.8571\n",
            "Epoch 46/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.3928 - accuracy: 0.9129 - val_loss: 0.5022 - val_accuracy: 0.8571\n",
            "Epoch 47/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.3496 - accuracy: 0.9380 - val_loss: 0.5069 - val_accuracy: 0.8571\n",
            "Epoch 48/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.2671 - accuracy: 0.9775 - val_loss: 0.5110 - val_accuracy: 0.8571\n",
            "Epoch 49/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.3913 - accuracy: 0.9078 - val_loss: 0.5079 - val_accuracy: 0.8571\n",
            "Epoch 50/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.3544 - accuracy: 0.9384 - val_loss: 0.5068 - val_accuracy: 0.8333\n",
            "Epoch 51/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.2905 - accuracy: 0.9697 - val_loss: 0.5000 - val_accuracy: 0.8333\n",
            "Epoch 52/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.3289 - accuracy: 0.9177 - val_loss: 0.4898 - val_accuracy: 0.8333\n",
            "Epoch 53/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.3612 - accuracy: 0.9294 - val_loss: 0.4813 - val_accuracy: 0.8333\n",
            "Epoch 54/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.4268 - accuracy: 0.9009 - val_loss: 0.4864 - val_accuracy: 0.8333\n",
            "Epoch 55/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.2808 - accuracy: 0.9604 - val_loss: 0.4898 - val_accuracy: 0.8333\n",
            "Epoch 56/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.3715 - accuracy: 0.9274 - val_loss: 0.4971 - val_accuracy: 0.8333\n",
            "Epoch 57/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.2937 - accuracy: 0.9656 - val_loss: 0.4968 - val_accuracy: 0.8571\n",
            "Epoch 58/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.4404 - accuracy: 0.8807 - val_loss: 0.4875 - val_accuracy: 0.8571\n",
            "Epoch 59/90\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.3969 - accuracy: 0.9454 - val_loss: 0.4958 - val_accuracy: 0.8571\n",
            "Epoch 60/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.3298 - accuracy: 0.9552 - val_loss: 0.4684 - val_accuracy: 0.8571\n",
            "Epoch 61/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.2935 - accuracy: 0.9593 - val_loss: 0.4703 - val_accuracy: 0.8571\n",
            "Epoch 62/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.3046 - accuracy: 0.9560 - val_loss: 0.4755 - val_accuracy: 0.8571\n",
            "Epoch 63/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.3180 - accuracy: 0.9429 - val_loss: 0.4728 - val_accuracy: 0.8571\n",
            "Epoch 64/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.2974 - accuracy: 0.9450 - val_loss: 0.4634 - val_accuracy: 0.8571\n",
            "Epoch 65/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.2507 - accuracy: 0.9779 - val_loss: 0.4699 - val_accuracy: 0.8571\n",
            "Epoch 66/90\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.2583 - accuracy: 0.9620 - val_loss: 0.4673 - val_accuracy: 0.8571\n",
            "Epoch 67/90\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.2579 - accuracy: 0.9716 - val_loss: 0.4653 - val_accuracy: 0.8571\n",
            "Epoch 68/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.2744 - accuracy: 0.9729 - val_loss: 0.4599 - val_accuracy: 0.8571\n",
            "Epoch 69/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.2792 - accuracy: 0.9545 - val_loss: 0.4464 - val_accuracy: 0.8571\n",
            "Epoch 70/90\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.2499 - accuracy: 0.9502 - val_loss: 0.4605 - val_accuracy: 0.8571\n",
            "Epoch 71/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.3246 - accuracy: 0.9339 - val_loss: 0.4749 - val_accuracy: 0.8571\n",
            "Epoch 72/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.2989 - accuracy: 0.9557 - val_loss: 0.4631 - val_accuracy: 0.8571\n",
            "Epoch 73/90\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.3214 - accuracy: 0.9058 - val_loss: 0.4558 - val_accuracy: 0.8571\n",
            "Epoch 74/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.3026 - accuracy: 0.9447 - val_loss: 0.4616 - val_accuracy: 0.8571\n",
            "Epoch 75/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.2731 - accuracy: 0.9556 - val_loss: 0.4927 - val_accuracy: 0.8571\n",
            "Epoch 76/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.2603 - accuracy: 0.9581 - val_loss: 0.4689 - val_accuracy: 0.8571\n",
            "Epoch 77/90\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.2443 - accuracy: 0.9676 - val_loss: 0.4691 - val_accuracy: 0.8571\n",
            "Epoch 78/90\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.2767 - accuracy: 0.9498 - val_loss: 0.4889 - val_accuracy: 0.8571\n",
            "Epoch 79/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.2632 - accuracy: 0.9533 - val_loss: 0.4728 - val_accuracy: 0.8571\n",
            "Epoch 80/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.2652 - accuracy: 0.9615 - val_loss: 0.4778 - val_accuracy: 0.8571\n",
            "Epoch 81/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.2870 - accuracy: 0.9336 - val_loss: 0.4768 - val_accuracy: 0.8571\n",
            "Epoch 82/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.2548 - accuracy: 0.9444 - val_loss: 0.4614 - val_accuracy: 0.8571\n",
            "Epoch 83/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.2258 - accuracy: 0.9729 - val_loss: 0.4934 - val_accuracy: 0.8571\n",
            "Epoch 84/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.3601 - accuracy: 0.8978 - val_loss: 0.4841 - val_accuracy: 0.8571\n",
            "Epoch 85/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.2238 - accuracy: 0.9643 - val_loss: 0.4828 - val_accuracy: 0.8810\n",
            "Epoch 86/90\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.3471 - accuracy: 0.9281 - val_loss: 0.4739 - val_accuracy: 0.8810\n",
            "Epoch 87/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.2972 - accuracy: 0.9257 - val_loss: 0.4771 - val_accuracy: 0.8810\n",
            "Epoch 88/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.2551 - accuracy: 0.9604 - val_loss: 0.4549 - val_accuracy: 0.8571\n",
            "Epoch 89/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.2371 - accuracy: 0.9592 - val_loss: 0.4684 - val_accuracy: 0.8571\n",
            "Epoch 90/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.3040 - accuracy: 0.9669 - val_loss: 0.4968 - val_accuracy: 0.8571\n",
            "processing fold # 2\n",
            "Epoch 1/90\n",
            "42/42 [==============================] - 1s 8ms/step - loss: 1.1923 - accuracy: 0.4209 - val_loss: 1.1048 - val_accuracy: 0.7381\n",
            "Epoch 2/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 1.1055 - accuracy: 0.5895 - val_loss: 1.0633 - val_accuracy: 0.7381\n",
            "Epoch 3/90\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 1.0570 - accuracy: 0.5894 - val_loss: 1.0244 - val_accuracy: 0.7857\n",
            "Epoch 4/90\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 1.0202 - accuracy: 0.6469 - val_loss: 0.9860 - val_accuracy: 0.7381\n",
            "Epoch 5/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.9989 - accuracy: 0.7023 - val_loss: 0.9503 - val_accuracy: 0.7381\n",
            "Epoch 6/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.9351 - accuracy: 0.7392 - val_loss: 0.9161 - val_accuracy: 0.7619\n",
            "Epoch 7/90\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.9186 - accuracy: 0.7489 - val_loss: 0.8851 - val_accuracy: 0.7857\n",
            "Epoch 8/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.8467 - accuracy: 0.8364 - val_loss: 0.8510 - val_accuracy: 0.8095\n",
            "Epoch 9/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.8360 - accuracy: 0.7948 - val_loss: 0.8161 - val_accuracy: 0.8095\n",
            "Epoch 10/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.8749 - accuracy: 0.7902 - val_loss: 0.7821 - val_accuracy: 0.7857\n",
            "Epoch 11/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.7717 - accuracy: 0.8368 - val_loss: 0.7545 - val_accuracy: 0.7857\n",
            "Epoch 12/90\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.7374 - accuracy: 0.8575 - val_loss: 0.7313 - val_accuracy: 0.7857\n",
            "Epoch 13/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.7903 - accuracy: 0.8038 - val_loss: 0.7146 - val_accuracy: 0.7857\n",
            "Epoch 14/90\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.6654 - accuracy: 0.8782 - val_loss: 0.6982 - val_accuracy: 0.7857\n",
            "Epoch 15/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.6978 - accuracy: 0.8702 - val_loss: 0.6790 - val_accuracy: 0.7857\n",
            "Epoch 16/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.6552 - accuracy: 0.8791 - val_loss: 0.6713 - val_accuracy: 0.8095\n",
            "Epoch 17/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.6372 - accuracy: 0.8740 - val_loss: 0.6558 - val_accuracy: 0.8095\n",
            "Epoch 18/90\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.6661 - accuracy: 0.8526 - val_loss: 0.6397 - val_accuracy: 0.8333\n",
            "Epoch 19/90\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.6194 - accuracy: 0.8322 - val_loss: 0.6270 - val_accuracy: 0.8333\n",
            "Epoch 20/90\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.5447 - accuracy: 0.9042 - val_loss: 0.6167 - val_accuracy: 0.8333\n",
            "Epoch 21/90\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.5560 - accuracy: 0.8985 - val_loss: 0.6127 - val_accuracy: 0.8095\n",
            "Epoch 22/90\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.5631 - accuracy: 0.8667 - val_loss: 0.5953 - val_accuracy: 0.8095\n",
            "Epoch 23/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.5451 - accuracy: 0.9041 - val_loss: 0.5874 - val_accuracy: 0.8095\n",
            "Epoch 24/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.4971 - accuracy: 0.9084 - val_loss: 0.5807 - val_accuracy: 0.8095\n",
            "Epoch 25/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.5100 - accuracy: 0.8868 - val_loss: 0.5689 - val_accuracy: 0.8095\n",
            "Epoch 26/90\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.5661 - accuracy: 0.8792 - val_loss: 0.5581 - val_accuracy: 0.8095\n",
            "Epoch 27/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.5704 - accuracy: 0.8626 - val_loss: 0.5580 - val_accuracy: 0.8095\n",
            "Epoch 28/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.5008 - accuracy: 0.8842 - val_loss: 0.5486 - val_accuracy: 0.8095\n",
            "Epoch 29/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.4955 - accuracy: 0.8559 - val_loss: 0.5530 - val_accuracy: 0.8333\n",
            "Epoch 30/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.5124 - accuracy: 0.8630 - val_loss: 0.5346 - val_accuracy: 0.8333\n",
            "Epoch 31/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.4488 - accuracy: 0.9170 - val_loss: 0.5280 - val_accuracy: 0.8333\n",
            "Epoch 32/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.4167 - accuracy: 0.9054 - val_loss: 0.5219 - val_accuracy: 0.8333\n",
            "Epoch 33/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.4289 - accuracy: 0.8993 - val_loss: 0.5155 - val_accuracy: 0.8333\n",
            "Epoch 34/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.3971 - accuracy: 0.9315 - val_loss: 0.5072 - val_accuracy: 0.8333\n",
            "Epoch 35/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.5117 - accuracy: 0.8758 - val_loss: 0.5048 - val_accuracy: 0.8333\n",
            "Epoch 36/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.4892 - accuracy: 0.8958 - val_loss: 0.5035 - val_accuracy: 0.8333\n",
            "Epoch 37/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.5178 - accuracy: 0.8737 - val_loss: 0.5040 - val_accuracy: 0.8095\n",
            "Epoch 38/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.3669 - accuracy: 0.9255 - val_loss: 0.5044 - val_accuracy: 0.8095\n",
            "Epoch 39/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.3487 - accuracy: 0.9444 - val_loss: 0.4985 - val_accuracy: 0.8333\n",
            "Epoch 40/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.3906 - accuracy: 0.9323 - val_loss: 0.4908 - val_accuracy: 0.8095\n",
            "Epoch 41/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.3601 - accuracy: 0.9022 - val_loss: 0.4845 - val_accuracy: 0.8095\n",
            "Epoch 42/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.4019 - accuracy: 0.9410 - val_loss: 0.4783 - val_accuracy: 0.8095\n",
            "Epoch 43/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.3477 - accuracy: 0.9305 - val_loss: 0.4713 - val_accuracy: 0.8095\n",
            "Epoch 44/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.3202 - accuracy: 0.9532 - val_loss: 0.4710 - val_accuracy: 0.8095\n",
            "Epoch 45/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.3631 - accuracy: 0.9319 - val_loss: 0.4628 - val_accuracy: 0.8333\n",
            "Epoch 46/90\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.3838 - accuracy: 0.9257 - val_loss: 0.4595 - val_accuracy: 0.8095\n",
            "Epoch 47/90\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.3397 - accuracy: 0.9438 - val_loss: 0.4687 - val_accuracy: 0.8095\n",
            "Epoch 48/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.3462 - accuracy: 0.9433 - val_loss: 0.4728 - val_accuracy: 0.8095\n",
            "Epoch 49/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.3481 - accuracy: 0.9500 - val_loss: 0.4526 - val_accuracy: 0.8095\n",
            "Epoch 50/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.3690 - accuracy: 0.9245 - val_loss: 0.4511 - val_accuracy: 0.8095\n",
            "Epoch 51/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.3919 - accuracy: 0.8925 - val_loss: 0.4718 - val_accuracy: 0.8095\n",
            "Epoch 52/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.3682 - accuracy: 0.9011 - val_loss: 0.4630 - val_accuracy: 0.8095\n",
            "Epoch 53/90\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.3684 - accuracy: 0.9127 - val_loss: 0.4586 - val_accuracy: 0.8095\n",
            "Epoch 54/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.3645 - accuracy: 0.9004 - val_loss: 0.4546 - val_accuracy: 0.8095\n",
            "Epoch 55/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.3405 - accuracy: 0.9228 - val_loss: 0.4491 - val_accuracy: 0.8095\n",
            "Epoch 56/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.3848 - accuracy: 0.9157 - val_loss: 0.4473 - val_accuracy: 0.8095\n",
            "Epoch 57/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.3412 - accuracy: 0.9321 - val_loss: 0.4340 - val_accuracy: 0.8095\n",
            "Epoch 58/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.3630 - accuracy: 0.9312 - val_loss: 0.4361 - val_accuracy: 0.8095\n",
            "Epoch 59/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.3522 - accuracy: 0.9350 - val_loss: 0.4310 - val_accuracy: 0.8095\n",
            "Epoch 60/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.4064 - accuracy: 0.8894 - val_loss: 0.4435 - val_accuracy: 0.8095\n",
            "Epoch 61/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.3742 - accuracy: 0.8946 - val_loss: 0.4378 - val_accuracy: 0.8095\n",
            "Epoch 62/90\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.3651 - accuracy: 0.9215 - val_loss: 0.4193 - val_accuracy: 0.8095\n",
            "Epoch 63/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.3342 - accuracy: 0.9470 - val_loss: 0.4326 - val_accuracy: 0.8095\n",
            "Epoch 64/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.3154 - accuracy: 0.9227 - val_loss: 0.4377 - val_accuracy: 0.8095\n",
            "Epoch 65/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.3449 - accuracy: 0.9254 - val_loss: 0.4378 - val_accuracy: 0.8095\n",
            "Epoch 66/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.3553 - accuracy: 0.9138 - val_loss: 0.4327 - val_accuracy: 0.8095\n",
            "Epoch 67/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.3251 - accuracy: 0.9328 - val_loss: 0.4290 - val_accuracy: 0.8095\n",
            "Epoch 68/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.3659 - accuracy: 0.9207 - val_loss: 0.4317 - val_accuracy: 0.8095\n",
            "Epoch 69/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.4132 - accuracy: 0.8828 - val_loss: 0.4224 - val_accuracy: 0.8095\n",
            "Epoch 70/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.2809 - accuracy: 0.9478 - val_loss: 0.4230 - val_accuracy: 0.8095\n",
            "Epoch 71/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.3236 - accuracy: 0.9116 - val_loss: 0.4343 - val_accuracy: 0.8095\n",
            "Epoch 72/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.3073 - accuracy: 0.9570 - val_loss: 0.4346 - val_accuracy: 0.8095\n",
            "Epoch 73/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.2688 - accuracy: 0.9658 - val_loss: 0.4285 - val_accuracy: 0.8095\n",
            "Epoch 74/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.3451 - accuracy: 0.9303 - val_loss: 0.4255 - val_accuracy: 0.8095\n",
            "Epoch 75/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.3549 - accuracy: 0.9180 - val_loss: 0.4161 - val_accuracy: 0.8095\n",
            "Epoch 76/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.2916 - accuracy: 0.9579 - val_loss: 0.4170 - val_accuracy: 0.8095\n",
            "Epoch 77/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.2664 - accuracy: 0.9463 - val_loss: 0.4042 - val_accuracy: 0.8333\n",
            "Epoch 78/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.3156 - accuracy: 0.9250 - val_loss: 0.4119 - val_accuracy: 0.8333\n",
            "Epoch 79/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.2861 - accuracy: 0.9348 - val_loss: 0.4040 - val_accuracy: 0.8095\n",
            "Epoch 80/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.3644 - accuracy: 0.9034 - val_loss: 0.4232 - val_accuracy: 0.8095\n",
            "Epoch 81/90\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.2699 - accuracy: 0.9441 - val_loss: 0.4208 - val_accuracy: 0.8095\n",
            "Epoch 82/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.3690 - accuracy: 0.9202 - val_loss: 0.4266 - val_accuracy: 0.8095\n",
            "Epoch 83/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.2638 - accuracy: 0.9570 - val_loss: 0.4127 - val_accuracy: 0.8095\n",
            "Epoch 84/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.3129 - accuracy: 0.9144 - val_loss: 0.4214 - val_accuracy: 0.8095\n",
            "Epoch 85/90\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.2768 - accuracy: 0.9653 - val_loss: 0.3959 - val_accuracy: 0.8095\n",
            "Epoch 86/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.2987 - accuracy: 0.9612 - val_loss: 0.3880 - val_accuracy: 0.8095\n",
            "Epoch 87/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.3384 - accuracy: 0.8898 - val_loss: 0.4042 - val_accuracy: 0.8095\n",
            "Epoch 88/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.3104 - accuracy: 0.9198 - val_loss: 0.4125 - val_accuracy: 0.8095\n",
            "Epoch 89/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.2657 - accuracy: 0.9342 - val_loss: 0.4155 - val_accuracy: 0.8095\n",
            "Epoch 90/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.2758 - accuracy: 0.9614 - val_loss: 0.4221 - val_accuracy: 0.8095\n",
            "processing fold # 3\n",
            "Epoch 1/90\n",
            "42/42 [==============================] - 1s 8ms/step - loss: 1.2287 - accuracy: 0.4532 - val_loss: 1.1584 - val_accuracy: 0.5714\n",
            "Epoch 2/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 1.1966 - accuracy: 0.5039 - val_loss: 1.0976 - val_accuracy: 0.7857\n",
            "Epoch 3/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 1.0915 - accuracy: 0.6527 - val_loss: 1.0502 - val_accuracy: 0.8571\n",
            "Epoch 4/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 1.1017 - accuracy: 0.6396 - val_loss: 1.0150 - val_accuracy: 0.8333\n",
            "Epoch 5/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 1.0573 - accuracy: 0.5997 - val_loss: 0.9806 - val_accuracy: 0.9048\n",
            "Epoch 6/90\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 1.0032 - accuracy: 0.7025 - val_loss: 0.9475 - val_accuracy: 0.9048\n",
            "Epoch 7/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.9579 - accuracy: 0.8083 - val_loss: 0.9156 - val_accuracy: 0.8810\n",
            "Epoch 8/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.9575 - accuracy: 0.7111 - val_loss: 0.8845 - val_accuracy: 0.9048\n",
            "Epoch 9/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.8841 - accuracy: 0.7702 - val_loss: 0.8496 - val_accuracy: 0.9048\n",
            "Epoch 10/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.9409 - accuracy: 0.7527 - val_loss: 0.8217 - val_accuracy: 0.8810\n",
            "Epoch 11/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.8001 - accuracy: 0.8655 - val_loss: 0.7899 - val_accuracy: 0.9048\n",
            "Epoch 12/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.8406 - accuracy: 0.8058 - val_loss: 0.7608 - val_accuracy: 0.9048\n",
            "Epoch 13/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.7898 - accuracy: 0.8053 - val_loss: 0.7339 - val_accuracy: 0.8810\n",
            "Epoch 14/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.8800 - accuracy: 0.7395 - val_loss: 0.7100 - val_accuracy: 0.8810\n",
            "Epoch 15/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.7358 - accuracy: 0.8486 - val_loss: 0.6851 - val_accuracy: 0.8810\n",
            "Epoch 16/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.7472 - accuracy: 0.8390 - val_loss: 0.6657 - val_accuracy: 0.8810\n",
            "Epoch 17/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.7275 - accuracy: 0.8563 - val_loss: 0.6387 - val_accuracy: 0.8810\n",
            "Epoch 18/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.6744 - accuracy: 0.8718 - val_loss: 0.6197 - val_accuracy: 0.9048\n",
            "Epoch 19/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.7048 - accuracy: 0.8302 - val_loss: 0.6066 - val_accuracy: 0.8810\n",
            "Epoch 20/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.6276 - accuracy: 0.8587 - val_loss: 0.5857 - val_accuracy: 0.9048\n",
            "Epoch 21/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.6797 - accuracy: 0.8041 - val_loss: 0.5711 - val_accuracy: 0.9286\n",
            "Epoch 22/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.6166 - accuracy: 0.8834 - val_loss: 0.5496 - val_accuracy: 0.9524\n",
            "Epoch 23/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.6286 - accuracy: 0.8308 - val_loss: 0.5364 - val_accuracy: 0.9286\n",
            "Epoch 24/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.5841 - accuracy: 0.8539 - val_loss: 0.5242 - val_accuracy: 0.9286\n",
            "Epoch 25/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.5582 - accuracy: 0.8653 - val_loss: 0.5075 - val_accuracy: 0.9286\n",
            "Epoch 26/90\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.5854 - accuracy: 0.8313 - val_loss: 0.4892 - val_accuracy: 0.9524\n",
            "Epoch 27/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.5060 - accuracy: 0.8914 - val_loss: 0.4769 - val_accuracy: 0.9524\n",
            "Epoch 28/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.5554 - accuracy: 0.8225 - val_loss: 0.4589 - val_accuracy: 0.9524\n",
            "Epoch 29/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.5773 - accuracy: 0.8149 - val_loss: 0.4504 - val_accuracy: 0.9524\n",
            "Epoch 30/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.4989 - accuracy: 0.8959 - val_loss: 0.4404 - val_accuracy: 0.9524\n",
            "Epoch 31/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.5163 - accuracy: 0.8908 - val_loss: 0.4353 - val_accuracy: 0.9524\n",
            "Epoch 32/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.5584 - accuracy: 0.8733 - val_loss: 0.4295 - val_accuracy: 0.9524\n",
            "Epoch 33/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.4769 - accuracy: 0.9004 - val_loss: 0.4300 - val_accuracy: 0.9524\n",
            "Epoch 34/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.5976 - accuracy: 0.7866 - val_loss: 0.4190 - val_accuracy: 0.9524\n",
            "Epoch 35/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.4488 - accuracy: 0.8992 - val_loss: 0.4180 - val_accuracy: 0.9524\n",
            "Epoch 36/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.5139 - accuracy: 0.8504 - val_loss: 0.4119 - val_accuracy: 0.9524\n",
            "Epoch 37/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.4948 - accuracy: 0.8496 - val_loss: 0.4046 - val_accuracy: 0.9762\n",
            "Epoch 38/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.4484 - accuracy: 0.8927 - val_loss: 0.3950 - val_accuracy: 0.9524\n",
            "Epoch 39/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.4555 - accuracy: 0.9013 - val_loss: 0.3862 - val_accuracy: 0.9524\n",
            "Epoch 40/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.4808 - accuracy: 0.8834 - val_loss: 0.3831 - val_accuracy: 0.9524\n",
            "Epoch 41/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.4085 - accuracy: 0.9152 - val_loss: 0.3858 - val_accuracy: 0.9524\n",
            "Epoch 42/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.4178 - accuracy: 0.8887 - val_loss: 0.3769 - val_accuracy: 0.9762\n",
            "Epoch 43/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.3914 - accuracy: 0.9229 - val_loss: 0.3755 - val_accuracy: 0.9524\n",
            "Epoch 44/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.4903 - accuracy: 0.8792 - val_loss: 0.3713 - val_accuracy: 0.9524\n",
            "Epoch 45/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.4174 - accuracy: 0.9226 - val_loss: 0.3743 - val_accuracy: 0.9762\n",
            "Epoch 46/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.4165 - accuracy: 0.9104 - val_loss: 0.3725 - val_accuracy: 0.9762\n",
            "Epoch 47/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.4299 - accuracy: 0.8945 - val_loss: 0.3607 - val_accuracy: 0.9524\n",
            "Epoch 48/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.3734 - accuracy: 0.8944 - val_loss: 0.3447 - val_accuracy: 0.9524\n",
            "Epoch 49/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.4337 - accuracy: 0.8747 - val_loss: 0.3457 - val_accuracy: 0.9762\n",
            "Epoch 50/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.4132 - accuracy: 0.8901 - val_loss: 0.3439 - val_accuracy: 0.9762\n",
            "Epoch 51/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.3588 - accuracy: 0.9494 - val_loss: 0.3405 - val_accuracy: 0.9762\n",
            "Epoch 52/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.4119 - accuracy: 0.9119 - val_loss: 0.3407 - val_accuracy: 0.9762\n",
            "Epoch 53/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.3740 - accuracy: 0.8966 - val_loss: 0.3315 - val_accuracy: 0.9762\n",
            "Epoch 54/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.4131 - accuracy: 0.9044 - val_loss: 0.3351 - val_accuracy: 0.9762\n",
            "Epoch 55/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.3524 - accuracy: 0.9174 - val_loss: 0.3374 - val_accuracy: 0.9762\n",
            "Epoch 56/90\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.4110 - accuracy: 0.8964 - val_loss: 0.3421 - val_accuracy: 0.9762\n",
            "Epoch 57/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.3640 - accuracy: 0.8889 - val_loss: 0.3370 - val_accuracy: 0.9762\n",
            "Epoch 58/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.3254 - accuracy: 0.9582 - val_loss: 0.3255 - val_accuracy: 0.9762\n",
            "Epoch 59/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.3797 - accuracy: 0.9242 - val_loss: 0.3319 - val_accuracy: 0.9762\n",
            "Epoch 60/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.3380 - accuracy: 0.9259 - val_loss: 0.3296 - val_accuracy: 0.9762\n",
            "Epoch 61/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.3843 - accuracy: 0.9198 - val_loss: 0.3294 - val_accuracy: 0.9762\n",
            "Epoch 62/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.2886 - accuracy: 0.9543 - val_loss: 0.3353 - val_accuracy: 0.9762\n",
            "Epoch 63/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.3421 - accuracy: 0.9302 - val_loss: 0.3207 - val_accuracy: 0.9524\n",
            "Epoch 64/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.3398 - accuracy: 0.9253 - val_loss: 0.3204 - val_accuracy: 0.9762\n",
            "Epoch 65/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.3405 - accuracy: 0.9397 - val_loss: 0.3128 - val_accuracy: 0.9762\n",
            "Epoch 66/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.3032 - accuracy: 0.9605 - val_loss: 0.3211 - val_accuracy: 0.9762\n",
            "Epoch 67/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.3738 - accuracy: 0.9143 - val_loss: 0.3145 - val_accuracy: 0.9762\n",
            "Epoch 68/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.3216 - accuracy: 0.9349 - val_loss: 0.3215 - val_accuracy: 0.9762\n",
            "Epoch 69/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.3749 - accuracy: 0.9215 - val_loss: 0.3036 - val_accuracy: 0.9762\n",
            "Epoch 70/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.2972 - accuracy: 0.9548 - val_loss: 0.3030 - val_accuracy: 0.9762\n",
            "Epoch 71/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.3244 - accuracy: 0.9390 - val_loss: 0.2958 - val_accuracy: 0.9762\n",
            "Epoch 72/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.3044 - accuracy: 0.9332 - val_loss: 0.2923 - val_accuracy: 0.9762\n",
            "Epoch 73/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.2630 - accuracy: 0.9794 - val_loss: 0.2875 - val_accuracy: 0.9762\n",
            "Epoch 74/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.2992 - accuracy: 0.9553 - val_loss: 0.2975 - val_accuracy: 0.9762\n",
            "Epoch 75/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.3309 - accuracy: 0.9441 - val_loss: 0.2929 - val_accuracy: 0.9762\n",
            "Epoch 76/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.3833 - accuracy: 0.9203 - val_loss: 0.2942 - val_accuracy: 0.9762\n",
            "Epoch 77/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.3423 - accuracy: 0.9323 - val_loss: 0.2924 - val_accuracy: 0.9762\n",
            "Epoch 78/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.3444 - accuracy: 0.9147 - val_loss: 0.2942 - val_accuracy: 0.9762\n",
            "Epoch 79/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.3042 - accuracy: 0.9293 - val_loss: 0.2845 - val_accuracy: 0.9762\n",
            "Epoch 80/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.2968 - accuracy: 0.9514 - val_loss: 0.2884 - val_accuracy: 0.9762\n",
            "Epoch 81/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.2853 - accuracy: 0.9670 - val_loss: 0.2801 - val_accuracy: 0.9762\n",
            "Epoch 82/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.2878 - accuracy: 0.9490 - val_loss: 0.2710 - val_accuracy: 0.9762\n",
            "Epoch 83/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.3295 - accuracy: 0.9205 - val_loss: 0.2752 - val_accuracy: 0.9762\n",
            "Epoch 84/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.3989 - accuracy: 0.8896 - val_loss: 0.2749 - val_accuracy: 0.9762\n",
            "Epoch 85/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.2942 - accuracy: 0.9475 - val_loss: 0.2880 - val_accuracy: 0.9524\n",
            "Epoch 86/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.3837 - accuracy: 0.8938 - val_loss: 0.2873 - val_accuracy: 0.9524\n",
            "Epoch 87/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.3171 - accuracy: 0.9318 - val_loss: 0.2883 - val_accuracy: 0.9524\n",
            "Epoch 88/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.2533 - accuracy: 0.9668 - val_loss: 0.2795 - val_accuracy: 0.9524\n",
            "Epoch 89/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.2940 - accuracy: 0.9494 - val_loss: 0.2887 - val_accuracy: 0.9524\n",
            "Epoch 90/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.2709 - accuracy: 0.9569 - val_loss: 0.2880 - val_accuracy: 0.9524\n",
            "processing fold # 4\n",
            "Epoch 1/90\n",
            "42/42 [==============================] - 1s 8ms/step - loss: 1.2165 - accuracy: 0.3179 - val_loss: 1.0564 - val_accuracy: 0.6905\n",
            "Epoch 2/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 1.0893 - accuracy: 0.5663 - val_loss: 1.0129 - val_accuracy: 0.7619\n",
            "Epoch 3/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 1.0372 - accuracy: 0.7043 - val_loss: 0.9735 - val_accuracy: 0.7619\n",
            "Epoch 4/90\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 1.0895 - accuracy: 0.6198 - val_loss: 0.9413 - val_accuracy: 0.7857\n",
            "Epoch 5/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.9711 - accuracy: 0.7988 - val_loss: 0.9016 - val_accuracy: 0.7857\n",
            "Epoch 6/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.8647 - accuracy: 0.8584 - val_loss: 0.8622 - val_accuracy: 0.7857\n",
            "Epoch 7/90\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.8923 - accuracy: 0.7838 - val_loss: 0.8276 - val_accuracy: 0.7857\n",
            "Epoch 8/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.8652 - accuracy: 0.8296 - val_loss: 0.8049 - val_accuracy: 0.7857\n",
            "Epoch 9/90\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.8265 - accuracy: 0.8065 - val_loss: 0.7712 - val_accuracy: 0.7857\n",
            "Epoch 10/90\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.8148 - accuracy: 0.8510 - val_loss: 0.7465 - val_accuracy: 0.7857\n",
            "Epoch 11/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.7202 - accuracy: 0.8680 - val_loss: 0.7257 - val_accuracy: 0.8095\n",
            "Epoch 12/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.7459 - accuracy: 0.8275 - val_loss: 0.7139 - val_accuracy: 0.8095\n",
            "Epoch 13/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.7784 - accuracy: 0.8264 - val_loss: 0.7020 - val_accuracy: 0.8095\n",
            "Epoch 14/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.7373 - accuracy: 0.8511 - val_loss: 0.6892 - val_accuracy: 0.8333\n",
            "Epoch 15/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.7018 - accuracy: 0.8443 - val_loss: 0.6811 - val_accuracy: 0.8333\n",
            "Epoch 16/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.6007 - accuracy: 0.9134 - val_loss: 0.6701 - val_accuracy: 0.8333\n",
            "Epoch 17/90\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.6466 - accuracy: 0.8599 - val_loss: 0.6657 - val_accuracy: 0.8333\n",
            "Epoch 18/90\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.6728 - accuracy: 0.8739 - val_loss: 0.6484 - val_accuracy: 0.8571\n",
            "Epoch 19/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.6232 - accuracy: 0.9031 - val_loss: 0.6383 - val_accuracy: 0.8571\n",
            "Epoch 20/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.6135 - accuracy: 0.8244 - val_loss: 0.6280 - val_accuracy: 0.8571\n",
            "Epoch 21/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.6260 - accuracy: 0.8837 - val_loss: 0.6093 - val_accuracy: 0.8571\n",
            "Epoch 22/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.6434 - accuracy: 0.8300 - val_loss: 0.6045 - val_accuracy: 0.8333\n",
            "Epoch 23/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.4929 - accuracy: 0.9017 - val_loss: 0.6038 - val_accuracy: 0.8333\n",
            "Epoch 24/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.5012 - accuracy: 0.9030 - val_loss: 0.6077 - val_accuracy: 0.8333\n",
            "Epoch 25/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.5325 - accuracy: 0.8692 - val_loss: 0.5964 - val_accuracy: 0.8571\n",
            "Epoch 26/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.5397 - accuracy: 0.8574 - val_loss: 0.5797 - val_accuracy: 0.8571\n",
            "Epoch 27/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.4977 - accuracy: 0.9197 - val_loss: 0.5704 - val_accuracy: 0.8571\n",
            "Epoch 28/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.4509 - accuracy: 0.9313 - val_loss: 0.5630 - val_accuracy: 0.8810\n",
            "Epoch 29/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.4293 - accuracy: 0.9239 - val_loss: 0.5659 - val_accuracy: 0.8571\n",
            "Epoch 30/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.5295 - accuracy: 0.8849 - val_loss: 0.5617 - val_accuracy: 0.8571\n",
            "Epoch 31/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.4411 - accuracy: 0.9405 - val_loss: 0.5583 - val_accuracy: 0.8571\n",
            "Epoch 32/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.4393 - accuracy: 0.9045 - val_loss: 0.5435 - val_accuracy: 0.8810\n",
            "Epoch 33/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.4379 - accuracy: 0.9230 - val_loss: 0.5462 - val_accuracy: 0.8571\n",
            "Epoch 34/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.4522 - accuracy: 0.9187 - val_loss: 0.5464 - val_accuracy: 0.8810\n",
            "Epoch 35/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.3721 - accuracy: 0.9423 - val_loss: 0.5358 - val_accuracy: 0.8810\n",
            "Epoch 36/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.4663 - accuracy: 0.8971 - val_loss: 0.5266 - val_accuracy: 0.8810\n",
            "Epoch 37/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.4504 - accuracy: 0.8968 - val_loss: 0.5265 - val_accuracy: 0.8810\n",
            "Epoch 38/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.4046 - accuracy: 0.9242 - val_loss: 0.5202 - val_accuracy: 0.8810\n",
            "Epoch 39/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.4741 - accuracy: 0.8946 - val_loss: 0.5289 - val_accuracy: 0.8810\n",
            "Epoch 40/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.4140 - accuracy: 0.9203 - val_loss: 0.5329 - val_accuracy: 0.8810\n",
            "Epoch 41/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.4263 - accuracy: 0.9221 - val_loss: 0.5219 - val_accuracy: 0.8810\n",
            "Epoch 42/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.4244 - accuracy: 0.9045 - val_loss: 0.5197 - val_accuracy: 0.8810\n",
            "Epoch 43/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.3676 - accuracy: 0.9285 - val_loss: 0.5330 - val_accuracy: 0.8571\n",
            "Epoch 44/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.4433 - accuracy: 0.9224 - val_loss: 0.5240 - val_accuracy: 0.8571\n",
            "Epoch 45/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.4076 - accuracy: 0.9288 - val_loss: 0.5148 - val_accuracy: 0.8571\n",
            "Epoch 46/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.3799 - accuracy: 0.9320 - val_loss: 0.4963 - val_accuracy: 0.8810\n",
            "Epoch 47/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.3551 - accuracy: 0.9326 - val_loss: 0.4851 - val_accuracy: 0.8810\n",
            "Epoch 48/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.3610 - accuracy: 0.9198 - val_loss: 0.4934 - val_accuracy: 0.8810\n",
            "Epoch 49/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.3837 - accuracy: 0.9268 - val_loss: 0.4965 - val_accuracy: 0.8810\n",
            "Epoch 50/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.3387 - accuracy: 0.9549 - val_loss: 0.5065 - val_accuracy: 0.8571\n",
            "Epoch 51/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.3267 - accuracy: 0.9502 - val_loss: 0.5008 - val_accuracy: 0.8810\n",
            "Epoch 52/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.3013 - accuracy: 0.9641 - val_loss: 0.4879 - val_accuracy: 0.8810\n",
            "Epoch 53/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.4450 - accuracy: 0.8626 - val_loss: 0.4968 - val_accuracy: 0.8810\n",
            "Epoch 54/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.4209 - accuracy: 0.8840 - val_loss: 0.5038 - val_accuracy: 0.8571\n",
            "Epoch 55/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.4031 - accuracy: 0.9206 - val_loss: 0.5085 - val_accuracy: 0.8571\n",
            "Epoch 56/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.3524 - accuracy: 0.9303 - val_loss: 0.5139 - val_accuracy: 0.8333\n",
            "Epoch 57/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.3309 - accuracy: 0.9446 - val_loss: 0.5095 - val_accuracy: 0.8571\n",
            "Epoch 58/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.2626 - accuracy: 0.9738 - val_loss: 0.5034 - val_accuracy: 0.8571\n",
            "Epoch 59/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.3831 - accuracy: 0.8828 - val_loss: 0.5036 - val_accuracy: 0.8571\n",
            "Epoch 60/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.3000 - accuracy: 0.9456 - val_loss: 0.5012 - val_accuracy: 0.8571\n",
            "Epoch 61/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.3250 - accuracy: 0.9325 - val_loss: 0.5093 - val_accuracy: 0.8571\n",
            "Epoch 62/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.3048 - accuracy: 0.9595 - val_loss: 0.5271 - val_accuracy: 0.8571\n",
            "Epoch 63/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.3669 - accuracy: 0.9112 - val_loss: 0.5049 - val_accuracy: 0.8571\n",
            "Epoch 64/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.2799 - accuracy: 0.9632 - val_loss: 0.5289 - val_accuracy: 0.8810\n",
            "Epoch 65/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.3569 - accuracy: 0.9265 - val_loss: 0.5188 - val_accuracy: 0.8571\n",
            "Epoch 66/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.2636 - accuracy: 0.9630 - val_loss: 0.5135 - val_accuracy: 0.8571\n",
            "Epoch 67/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.3179 - accuracy: 0.9309 - val_loss: 0.5371 - val_accuracy: 0.8810\n",
            "Epoch 68/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.3306 - accuracy: 0.9059 - val_loss: 0.5306 - val_accuracy: 0.8810\n",
            "Epoch 69/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.3278 - accuracy: 0.8971 - val_loss: 0.5373 - val_accuracy: 0.8810\n",
            "Epoch 70/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.3422 - accuracy: 0.9232 - val_loss: 0.5504 - val_accuracy: 0.8810\n",
            "Epoch 71/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.3394 - accuracy: 0.9348 - val_loss: 0.5370 - val_accuracy: 0.8571\n",
            "Epoch 72/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.2755 - accuracy: 0.9444 - val_loss: 0.5605 - val_accuracy: 0.8571\n",
            "Epoch 73/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.3386 - accuracy: 0.9382 - val_loss: 0.5660 - val_accuracy: 0.8571\n",
            "Epoch 74/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.3251 - accuracy: 0.9305 - val_loss: 0.5654 - val_accuracy: 0.8571\n",
            "Epoch 75/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.2891 - accuracy: 0.9584 - val_loss: 0.5492 - val_accuracy: 0.8571\n",
            "Epoch 76/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.3018 - accuracy: 0.9369 - val_loss: 0.5569 - val_accuracy: 0.8571\n",
            "Epoch 77/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.3437 - accuracy: 0.9048 - val_loss: 0.5537 - val_accuracy: 0.8571\n",
            "Epoch 78/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.2853 - accuracy: 0.9253 - val_loss: 0.5623 - val_accuracy: 0.8810\n",
            "Epoch 79/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.2742 - accuracy: 0.9390 - val_loss: 0.5599 - val_accuracy: 0.8810\n",
            "Epoch 80/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.3079 - accuracy: 0.9366 - val_loss: 0.5672 - val_accuracy: 0.8333\n",
            "Epoch 81/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.2449 - accuracy: 0.9690 - val_loss: 0.5898 - val_accuracy: 0.8333\n",
            "Epoch 82/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.3293 - accuracy: 0.9232 - val_loss: 0.5847 - val_accuracy: 0.8333\n",
            "Epoch 83/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.2692 - accuracy: 0.9505 - val_loss: 0.5771 - val_accuracy: 0.8333\n",
            "Epoch 84/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.2541 - accuracy: 0.9606 - val_loss: 0.5948 - val_accuracy: 0.8333\n",
            "Epoch 85/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.2688 - accuracy: 0.9517 - val_loss: 0.5830 - val_accuracy: 0.8333\n",
            "Epoch 86/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.3719 - accuracy: 0.9292 - val_loss: 0.5766 - val_accuracy: 0.8333\n",
            "Epoch 87/90\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.2593 - accuracy: 0.9600 - val_loss: 0.5847 - val_accuracy: 0.8333\n",
            "Epoch 88/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.3001 - accuracy: 0.9271 - val_loss: 0.5935 - val_accuracy: 0.8571\n",
            "Epoch 89/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.2499 - accuracy: 0.9685 - val_loss: 0.6078 - val_accuracy: 0.8571\n",
            "Epoch 90/90\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.2538 - accuracy: 0.9472 - val_loss: 0.6094 - val_accuracy: 0.8333\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.9142857193946838,\n",
              " 0.9142857193946838,\n",
              " 0.8999999761581421,\n",
              " 0.9214285612106323,\n",
              " 0.9071428775787354]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 428
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "2pSjiDw6iUdv",
        "outputId": "a83639c6-de91-42d8-a31a-f095fe957050"
      },
      "source": [
        "plt.plot(range(1, len(ave_val_loss_hist)+1)[:], ave_val_loss_hist[:], \"bo\", label=\"Validation Loss\")\n",
        "plt.plot(range(1, len(ave_val_loss_hist)+1)[:], ave_loss_hist[:], \"b\", label=\"Training Loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Validation Loss\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "execution_count": 429,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "VShQoRrqulob",
        "outputId": "aa6cc11a-7045-4218-c778-21d0d02c922a"
      },
      "source": [
        "plt.plot(range(1, len(ave_val_acc_hist)+1)[:], ave_val_acc_hist[:], \"bo\", label=\"Validation Accuracy\")\n",
        "plt.plot(range(1, len(ave_val_acc_hist)+1)[:], ave_acc_hist[:], \"b\", label=\"Training Accuracy\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Validation Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 430,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXgUZbb48e8hoBA22URZg8oiiAEJboCAywwKAyoqIHjBBZTRUdxG1KswjvxwrsyMOm4XdzDCqCOKDsqVRYFBHQKIJgijQoAASgDZ1yTn98fbSTpJd6eT9JKkzud5+ul0VXXV6aap89a7lagqxhhjvKtGvAMwxhgTX5YIjDHG4ywRGGOMx1kiMMYYj7NEYIwxHlcz3gGUVdOmTTUpKSneYRhjTJWycuXKnaraLNC6KpcIkpKSSEtLi3cYxhhTpYjIpmDrrGrIGGM8zhKBMcZ4nCUCY4zxOEsExhjjcZYIjDHG4ywRGGOMx1kiMMYYj7NEYIwxldyRI/D738OWLdHZvyUCY4ypxH78EXr1giefhI8+is4xqtzIYmOMiYcdO+DTT6F1a+jTB0Sif8x334Wbb4aEBPjgAxg8ODrHsURgjDFBbN8Or78Oc+fCV19B/g0de/SAe++Fa66BWrUie8z16+HDD91jyRI47zz4+9+hbdvIHsefVQ0ZEyW7d0NKCnz5Zbwj8bZDh+D556FnT7j1Vti5s/T3pKfDjTdCUhI89BDk5MDkyfDvf8OLL8L+/XD99W79+PEwb56rxy/N4cMwfz5kZJRcl5XlTvqdOsH998PevfD//p9LBtFMAgCoapV69OjRQ42pCmbOVAXVoUPjHUnVs2eP6sKFqnl5RZcfOKA6dqxqq1aFjw4dVGfPLrmPXbtU//u/VZs0cf8OXbqo1qyp2qiR6osvqubkBD72gw+67RMTVW+/XfX770tuk5urOneu6lVXqdatW7j9H/9Ycr9Hj6q++qrq4MFuG3BxTJtW+PnWrlVt3Vq1fn3Vp59W3bSp7N9ZaYA0DXJejfuJvawPSwSmqhg1qvA//c8/xzua2Nm+XXXZspIn8bIYMcJ9dxddpPrtt25ZerrqmWeqiqhed53qTTe5R48ebtvx41UPH3Yn6ZdfVm3a1G175ZWqS5e6eNLTVfv1c9v37at6/HjR427a5P69rrvOJZJwHD6s+vHHLuGD6qWXqv70k1v36aeqHTu65W3auMTy0UcugYBLDv/8p0tOzZurrlpV/u+sNJYIjImx3FzVk09WTUlx/8uefDLeERXas8edGI8ejfy+s7JU27Vznzk5WfWNNwIfZ8cO1T/8QfXii917/H37rTuBX3aZauPGqgkJLjHUqeNOlgsWFN3+2DHV++93x+zWTfX8893fvXurfv11yWPn5an+7W9um+nTi6773e9cIti8ueyfPS/PJaDatVVPOUV1yBB3jNNPdyd//8SYl6f61FOqtWq5bdq3V92woezHLAtLBMbE2KpV7n/XG2+oXnihKxVWpIQcjsceU73kElcyfuop1eXLA2939dUutvr1Va+5xsW4f3/RbfLyVGfNUh0wQHXdupL7OHxY9auvin6mHTtUO3VSrVdPdepUVxUD7qR41VWqEyeqvvKK6q23upNl/tXS5ZcX3c/QoS62nTvdY9w4lxj693dXG8F8+KFLHCefrDpjRujvOy9PtVcvl1jyP/vPP7u4brop+PvCsWaNq66qXdtVFR0+HHzbr75SveMO991FmyUCY2Js6lT3v2v7dtXXXnN/L10aveMdOOBKzKeconrSSe54oDpnTtHtli51y8eMcSfYFi3c65NOUn3gAVc6z8hwJ11wJ+D27YtWkxw+7Ko/QLVzZ1cK3r7dlcbr1FH9/HO3XV5eYZVJp06Fpd8TT1S95RZXL/70027Za6+596xe7V4/+mjRuLdtc1dZpfnlF/ddhOPLL4se68EH3eddvz6894dy+LBLYpWJJQJjYqxfP1c1oupOTA0aqP7XfwXffuvWwnrl8vjHP9z/5vwG1p9+cifm5s0LT0h5earnnutO/gcPumW5ua4+/5prVGvUcCfr/AbVF15QXbJE9YQT3JXGsWPuMXiwO9a997pjQOF7P/kkeIzHj7uGV/8TZG6uap8+qg0buiT0m9+4pPTLL+X/Lspi2DCXvDIy3L/RtdfG5rjxYInAmAqaNs1VlQSyc2fR0uq+fe5k+sADhctuu82dcIqf4PbtcyfUmjVdafS881x1wpIlrtog0CNQ9cioUa5axL/xc/Vqt9/rr3evZ88uWvou7scfVe++2z2yswuXv/66e99tt6kOH+7+fu45ty4vz9XZDxvmqmbK4/vv3XeTnOz2PWVK+fZTHhs2uETXrJk7djQba+PNEoExFbB+vTtJt2lTsnpizx5Xgr3uusI66Q8+cP+zFi0q3C4tzS37wx9cA+bXX7vupS1auH3fcotLAOeeqwXVOsEeLVoUrXc+dszFMGZMydgnT3bvmT1bNSnJnWyDdZsMJb8xFlT/9Keyv780Tz3l9t20acn2imi791537Msvj+1xY80SgTFhOHYscP3yzTcXngSL1/NPn1647oUX3LLf/tb1LffvLZOXp9q9e8mTeo8erq7a3/btqvPmuW6FxR/5vV2ef75w+//7P7fsgw8Cf6Zu3VzVDbjujOWRk+MaNadNK9/7S5Ob6763d9+Nzv5D2b3bVUmtXh37Y8dSqEQgbn3VkZKSomlpafEOw1QhL74IHTtC//7Bt8nKggED4OBBWLkSGjd2y7dsgdNPd6NI334bxoxxo1Tz9enjRqomJcHixW4agqFD4cwz3RQB/rZsAf+fbr16cPHFbh6ZcKnChRfCTz/B999DzZpuZOvMmZCdDXXqlHzP11+7UbWXXeZGwBpvEpGVqpoScGWwDFFZH3ZFYMoiK8uVhE84IXhpOCOjcFRnrVqu/3d+Nc9dd7l69sxMVz/epIkrZauq/vCD2/fUqa7736mnupGu4Eru0TJ3rjvGzJmuJH3qqaWPXs7IiH2Vi6lcCHFFYHMNmUrt6FHIywu+rjTvvuueW7eGIUNg2bKi65cvh9694fhxN6fLn/7kZnn8299cCXv6dBg50s31MmIE7NoFCxa4986Y4WagHDUKmjWDt96Cbdvcul//unyfNxwDB0LXrjB1KnzxhZsY7eqrQ7+nc2d3BWJMQMEyRGV92BWBd/z0k+sJU7u2ateurtT7X//lRo42buwaWe+6K/QI2V693Ht/+skN8mnQwPWtf+IJN/K0Ro2iozrz8lQHDXJXEFdd5Y6xdq1bd/So61Y5apQriScluf70/v78Z9WBA6M/eOytt9xVwdlnu6uYPXuiezxT9RGvxmJgALAe+AGYGGB9W2Ah8A3wGdCqtH1aIvCOW2911TJ33ulOzh06qLZs6QY73Xab6ujR7hfcs2fg4fn51UKPPeZeb96s2ratFjTUdu/uBhP5d5VUdd1B86t4rr666LqxY11D8McfF1bPxMPx46qnneZi+PWv4xODqVrikgiABOBH4DTgBGAN0LnYNu8Ao31/XwzMLG2/lgi8ISPDldbvvDP0du+95wYjNWzoetr4yx+1+t13hcs2bXL96LdsCb3fZctUzzrLTRfgb/Fit8/Wrd1UCuGOYo2G//1fF8uLL8YvBlN1hEoEUes1JCIXAJNV9de+1w/6qqKm+m2TAQxQ1S0iIsBeVW0Qar/Wa8gbBg2CpUvdbfqaNg297caNro78xx/dPPJt2rjlvXvDvn3wzTeRiys31+1/2zY3X/2rr0Zu32WVkwNvvgnDh0Pt2vGLw1QNoXoNRbOxuCXgf6vlLN8yf2uA/Gauq4D6ItKk+I5EZJyIpIlIWnZ2dlSCNfGxe7e7H+vll7s7MwEsXAj//Cc8/HDpSQCgXTt47z3XqDx2rKv42boV/vUvuPbayMabkOBOvACjR0d232VVs6brzmpJwFRUvG9VeR/wrIiMAZYAW4Hc4hup6nRgOrgrglgGaKJn/36XAL7+2vV/79rV3f7vk09cqfvOO8PfV7t27ubev/0tvPKKuysVRD4RAEycCB06wEUXRX7fxsRDNBPBVqC13+tWvmUFVHUbvisCEakHDFXVPVGMycRIerobhHXBBXDPPW5Al79Dh1z1z8qVrjR/3nnwwAPwxBNufWpq2Uu6t94K77zjjte2rUssnTpF5vP4a9bMHcuY6iKabQQ1gf8Al+ASwArgelXN8NumKbBbVfNEZAqQq6qPhtqvtRFUft9/70rLx465kbpHj7qT/pVXFo6ifest1x//rbcKq1rAVed89RVMmAA1ylFxuXGjSwAHD8Jjj8Ejj0TmMxlT1YVqI4jaFYGq5ojIHcB8XA+iV1U1Q0Qew7VezwX6AVNFRHFVQ7dHKx4TG5s3wyWXuIbMpUtdHf9zz7lpGT76qHC7GjXgpZeKJgFw7QW9epX/+O3awV/+Ar/7Xcl9G2MCs7mGPGzlSujSpfyNjcePu5PtL7+4qp8OHdwJPzvbzbvTvXvhtkePuhGw+erVC68huLwOHLCRtJVZaqrrDLB5s2sPuuIKNw/S5s2F8zzt3u3WTZniRnfHKpZoHy9ebK4hU8J//uNGzd58c/n38ec/a8F9YvPvilWvXvBbJBqjqvrmm6qJiYUD+0p7JCa698QqlmgeL56wuYZMcTNmuJ/9K6+4+WrKautWmDTJleRWrXKltx073CyeF1wQ+XhN5ZWa6mZfrVHDPaemht5u1KjCXl3hOHTIldgjxT/e0aNLxnLokIsx1GepdoJliMr6sCuCisvNdTdZ6dPHTdnQrVvRO1v5O3jQja71v2etqrsj1Yknuhk4jXeFW6Iu61VA8YdI9OKN19VIrGE3pjH+8qdJSE1Vfftt9/czzxSu//xz1QED3DQK+f8hGjRwd5E6ftzdmhDc3a8qmzffdPMJibhn///EodaVZT/BtmvSxD3y3zN+fOB9lCVG/30U33+4J6hwY/RfF+5n8Z+7qfjD/33lTQD5j4SEyMRfnmO3bRve91zZWSIwRYwZ4+beP3jQzZJ52WXuRL96tZtZE9ykazfc4G6f+OabbmIzcDN5nn66e/jfLrEyCFU6LUtdcLRKuYmJ7oRUlhgrWlqtaEm8tGOLRH7fle0RqauReLNEYAocOOAadP0bidevd9Mug3t++GGXJPzl5bkJ3tq0cdsVn+CtuGCl3vKW2MMpKYcq0QUrDQYqaSYkBN+Pv0iUdP3jKO/7Ql0tRDLGSMZd/HsNVrKPxP4j8TlKuzorz7qy7CMS1VOWCEyBmTPdv/rnnxdd/uyzqtde63oThXLggLsReyjBStRlLQ2Xt6Rc/CESmZJr8ZJhZS4NV4USezhXNLGIP1K/s3h/V6WxRGAKXHqpart2rsE4WspaCg1VGotEiTCSpcpYlrYj8agsJepQ32Mkf0sV+fdULbzyjPe/W7DvuCJXCJYIjKq6OfhFVCdNiu5xKnMpNBKPqlCCjPVDJLzvo6wl22i3cVTV33B5rhAsEXjcsWOuSqhrV/cvXrzLZ1l60wR7XzzqdUt7VPRKI1L1xuU9RiTrzqPd6ya//SRUW055S7LR7PUUTGW9Kgj0nYfLEoFH/fKL6v/8T+FtF888U3X27KLblHdkZWUuDZdWPx5O6TXcOvbyflfl6c1Uke8/mv3wq1Nf+3yV+fdd3n9TSwQe4V+/Wb++u+k7uHv83nef6/FT1hJeMOGUmEortZa3xB5uD4tgMQYqvVak1004JbNIjW8Its9wek5FSnnjrWrKMqYjmr2Gwu3FVhpLBNXcsmWqv/qVu8dv8ZPp44+Xr3RTWmkjnDrUYCXv8vYUikT9cjTqqCtTP3OvlNi9JFL/ppYIqhn/ksopp6jWqhX8xByqD31ZS7n+xw2njjpYvXF5xw5UtH65ovuIRWk7ErxSYveSSPybWiKoRgKVDkKVzsvThz5So2ir2wnIStumKguVCGz20Srm4YdLzpaoGnz7GjVCry+ubVs3I+PDD7v3Nm3qHsFmjExIABFo0sQ9RNw+pk+vfnO6jxzpPlfbttX7cxrvsRvTVDFlPbGHKzHRndQAxo0Lf5pgEcjLi3w8xpjICnVjGrsiiIJg87MXX/7b34Y3j7u/1q3DiyH/3sCBtG0L48cHLtkGuuIIpU2b8Lc1xlROdkUQYampJUvUiYmuuuWNN0KfZGvVgs6dYeFCV80SyJAhMHdu6BhE3HOgf9rSSvBlueLIv4qwqhFjKj+7IoihQCXqQ4fcCbO0kvbx47BmDYwZE/hkPHWqSwL9+4cuibdpE3x9aSX4cEv4Vj9uTPVhiSAC/Kt8Nm0KvE1ubvj7++gj6N27cJ9NmrjS90MPQd26cOON7jhvvumW+0tMdDffnjIl+LpQAr2v+D7efBMyMy0JGFNtBOtOVFkfla37aLjdKiM5/45/l8VYjVi1PunGVG2E6D5qbQQVlJQU/Cogn4g7hec/R0Lbtq5Ubowx4bA2gijavDn0ev+Tf34yAFflU7cutGgRneMaY0y4LBFUULDG1bZt3aP4FYCq69rZuDGsWAFbt7rtInVcY4wpK0sEFRSqUTZYqT03Fz74AM48M/g+Qgmn0dcYY8JliSAE/95A+VMtFB8MdsMNUKdO4OkVgpXaExLgggsKXweausB/wJcXpm8wxsSPNRYHEWhgWCiBBlcF20efPrBkSeRiNcaY0lhjcTmUdaqFQ4fce/wVL+mfcopbfuutkYvTGGMqyhJBEOXplRPoPSNHum6eeXlw111u2aWXVig0Y4yJKEsEQZSnV05p71mwALp2hebNyxeTMcZEgyWCICLdk+fwYVi2zK4GjDGVjyWCIIrX7xfvuVN8Gucnn3QDxIK1vf/rX3D0qCUCY0zlUzPeAVRmI0eG301z3Di4/Xb4zW/g9dfdgDF/n37qppm+6KKIh2mMMRUS1SsCERkgIutF5AcRmRhgfRsRWSwiq0XkGxG5IprxRNOCBW5cwSefQPfu8OWXJddfcAHUqxeX8IwxJqioJQIRSQCeAy4HOgMjRKRzsc3+G3hbVbsDw4HnoxVPNP34I2zcCPfd56qAEhLcWIFHHnHdSnfuhNWrrVrIGFM5RfOK4FzgB1XdoKrHgNnAkGLbKNDA93dDYFsU4wko2G0ly2LBAvd86aXQsyesWgXDh8Pjj7s7jk2a5NoOLBEYYyqjMiUCEakhIg1K3xKAlsAWv9dZvmX+JgOjRCQLmAf8Lshxx4lImoikZWdnlyXkkPJH/m7a5E7Umza512VNBgsWQKtW0KGDe33SSTBzJnz2GdSvD88/Dw0auCRhjDGVTamJQETeEpEGIlIXSAfWisj9ETr+COB1VW0FXAHMFJESManqdFVNUdWUZs2aRejQwW8rWXyEcCi5ubBoEVx2WeEU0/n69nVXB88+C3/7G9S0pnljTCUUzqmps6ruE5GRwMfARGAl8GQp79sKtPZ73cq3zN/NwAAAVf1CRGoDTYEdYcRVYcFGD5dlVPHXX8Pu3cGrfWrVcr2JjDGmsgqnaqiWiNQCrgTmqupxXN1+aVYA7UWknYicgGsMnltsm83AJQAiciZQG4hc3U8pgo0ErlEj/DaDTz91z5dcEtHQjDEmZsJJBP8LZAJ1gSUi0hbYV9qbVDUHuAOYD3yH6x2UISKPichg32b3AmNFZA0wCxijMZwONdjo4dzc8NsMFiyAs8+2aSOMMVVXuaahFpGavhN9zEV6GurUVNcmsHmzuwrIzS25TbD7Ax8+DI0auaqfP/85YiEZY0zEVWgaahG5y9dYLCLyioisAi6OeJRx4j87aF5e4G2CtRnYtBHGmOognKqhm1R1H/AroBFwA/BEVKOKk2BtBsGWL1hg00YYY6q+cBJBfqfIK4CZqprht6xaCXX/4eJUYf58uPBCN9mcMcZUVeEkgpUi8n+4RDBfROoDQSpRqrZA9w4Odn/g6dNd19Hrrot9nMYYE0mlNhb7Bnh1Azao6h4RaQK0VNVvYhFgcbG6Z3Eo33wD553nBozNm+camY0xpjIL1Vhc6oAyVc0TkVbA9eKGzn6uqh9GOMYq4+BBGDbMTSMxY4YlAWNM1VdqIhCRJ4CeQH5v+jtF5AJVfSiqkVVSd9wB69e7huKTT453NMYYU3HhlGevAC5T1VdV9VXclBCDohtWdJV3xtEFC9xNZx55BC6uNh1ojTFeF+40aCcBu31/N4xSLDGRP+No/mRz+aOHofS7kS1b5hqRH3ggujEaY0wshXNFMBVYLSKvi8gbuAnnQtymvXKryIyj6elwxhllu6m9McZUduE0Fs8Skc9w7QQADwBtoxlUNFVkxtGMDDjrrMjGY4wx8RZWnxdV3a6qc32Pn4B3ohxX1JR19HC+I0fg+++hS5fIx2SMMfFU3s6PVXZkcVlGD/tbv95NSGdXBMaY6qa8iSBmU0VHWllGD/tLT3fPlgiMMdVN0DYCEfmQwCd8AZpELaIYGDmy9BN/cRkZboK59u2jE5MxxsRLqMbiaeVcVy2lp7ub059wQrwjMcaYyAqaCFT181gGUtmlp8O558Y7CmOMiTybKScMBw/Cxo3WPmCMqZ4sEYRh7Vr3bInAGFMdWSIIQ36PIRtDYIypjsKZfbQDcD9uNHHB9qrqmWnXMjKgdm047bR4R2KMMZEXzqRz7wAvAi8BudENp3JKT4fOnSEhId6RGGNM5IWTCHJU9YWoR1KJpafbtNPGmOornDaCD0XktyJyqog0zn9EPbJKYs8e2LrVGoqNMdVXOFcEo33P9/stU8ATNeYZGe7ZEoExproKZxrqdrEIpLKyOYaMMdVdOL2GagHjgYt8iz4D/ldVj0cxrkojPR3q14fWreMdiTHGREc4VUMvALWA532vb/AtuyVaQVUm337regxJlZ142xhjQgsnEfRU1WS/14tEZE20AqpMjh+HFSvg5pvjHYkxxkRPOL2GckXk9PwXInIaHhlPsHq1u59xnz7xjsQYY6InnCuC+4HFIrIBdy+CtsCNUY2qkli61D1bIjDGVGfh9BpaKCLtgY6+RetV9Wh0w6ocli6FM86AU06JdyTGGBM9oe5QdrGqLhKRq4utOkNEUNX3ohxbXOXlwbJlMHhwvCMxxpjoCnVF0BdYBPwmwDoFqnUiWLcOdu2yaiFjTPUX6g5lk3x/PqaqG/3XiUhYg8xEZADwNJAAvKyqTxRb/1egv+9lInCyqp4UZuxRZe0DxhivCKex+B/AOcWWvQv0CPUmEUkAngMuA7KAFSIyV1XX5m+jqnf7bf87oHuYcUfd0qXQvDmcfnrp2xpjTFUWqo2gE9AFaFisnaABUDuMfZ8L/KCqG3z7mw0MAdYG2X4EMCnIuphbutRdDdhAMmNMdRfqiqAjMAg4iaLtBPuBsWHsuyWwxe91FnBeoA1FpC3QDtcmEWj9OGAcQJs2bcI4dMVs3uwe994b9UMZY0zchWoj+AD4QEQuUNUvohzHcOBdVQ04UE1VpwPTAVJSUjTKsVj7gDHGU8JpI1gtIrfjqokKqoRU9aZS3rcV8J+qrZVvWSDDgdvDiCUmli6FBg3g7LPjHYkxxkRfOFNMzAROAX4NfI47oe8P430rgPYi0k5ETsCd7OcW38jXFtEIiPZVR9iWLoULL7RbUxpjvCGcRHCGqj4CHFTVN4CBBKnr96eqOcAdwHzgO+BtVc0QkcdExH+Y1nBgtqpGvconHLt2wdq10Lt3vCMxxpjYCCcR5N93YI+InAU0BE4OZ+eqOk9VO6jq6ao6xbfsUVWd67fNZFWdWNbAyyI1FZKSoEYN95yaGnzb+fPdc//+wbcxxpjqJJw2guki0gh4BFe1Uw94NKpRRVBqKowb52YRBdi0yb0GGDmy5PZz5ri5hc4/P3YxGmNMPEklqZEJW0pKiqalpYW9fVKSO/kX17YtZGYWXXb4MDRrBqNGwYsvVihMY4ypVERkpaqmBFoXakDZPaF2qqp/qWhgsbB5c/jLFyyAgwfhqquiG5MxxlQmoaqG6vueOwI9Kezx8xvg39EMKpLatAl8RRBoXNp770HDhtY+YIzxlqCNxar6B1X9A6676Dmqeq+q3oubYyj6w3sjZMoUSEwsuiwx0S33l5MDH34IgwbBCSfELj5jjIm3cHoNNQeO+b0+5ltWJYwcCdOnuzYBEfc8fXrJhuKlS13XUasWMsZ4TTi9hmYA/xaROb7XVwKvRy2iKBg5MnAPIX9z5kDt2jBgQGxiMsaYyiKcW1VOEZGPgfyZd25U1dXRDSu2VF0i+NWvoG7deEdjjDGxFarXUANV3ScijYFM3yN/XWNV3R398GIjLQ2ysuDxx+MdiTHGxF6oK4K3cNNQr8TdmjKf+F6fFsW4YuqDD9y8Qr8JdFNOY4yp5kJNQz3I9xzWbSmrsowM6NQJGjeOdyTGGBN7oaqGit+esghVXRX5cOJj2zZo2TLeURhjTHyEqhr6c4h1Clwc4VjiZts26Nw53lEYY0x8hKoa8sT42rw82L4dWrSIdyTGGBMf4YwjwDf9dGeK3qFsRrSCiqUdOyA31xKBMca7Sk0EIjIJ6IdLBPOAy4FluIFmVd62be7ZEoExxqvCmWLiGuAS4CdVvRFIxt2cplrITwTWWGyM8apwEsFhVc0DckSkAbCDojelr9LsisAY43XhtBGkichJwEu4wWUHqEQ3mq+orVvdZHTNq8w0esYYE1mhxhE8B7ylqr/1LXpRRD4BGqjqNzGJLga2bYOTT4ZateIdiTHGxEeoK4L/ANNE5FTgbWBWdZtsDmwwmTHGhLoxzdOqegHQF9gFvCoi60Rkkoh0iFmEUbZtm7UPGGO8rdTGYlXdpKp/UtXuwAjc/Qi+i3pkMbJ1qyUCY4y3lZoIRKSmiPxGRFKBj4H1wNVRjywGjh2D7GxLBMYYbwvVWHwZ7grgCtzN6mcD41T1YIxii7qffnLPlgiMMV4WqrH4Qdw9Ce5V1V9iFE9M2WAyY4wJPelctZldNBgbTGaMMeGNLK62tm51z5YIjDFe5ulEsG2bG0jWtGm8IzHGmPjxfCI49VSo4elvwRjjdZ4+BdpgMmOM8XgisMFkxhjj8URgVwTGGOPhRHDwIOzda2MIjDEmqolARAaIyHoR+UFEJgbZ5joRWSKBOFYAABTTSURBVCsiGSLyVjTj8bd9u3u2KwJjjNeFdfP68hCRBOA54DIgC1ghInNVda3fNu1xI5h7qeovInJytOIpzsYQGGOME80rgnOBH1R1g6oew81VNKTYNmOB5/KnsFDVHVGMpwgbVWyMMU40E0FLYIvf6yzfMn8dgA4i8i8R+VJEBgTakYiME5E0EUnLzs6OSHCWCIwxxol3Y3FNoD3QDzfT6Uu++yMXoarTVTVFVVOaNWsWkQNv2waJidCwYUR2Z4wxVVY0E8FWoLXf61a+Zf6ygLmqelxVN+Juj9k+ijEVBucbQyASi6MZY0zlFc1EsAJoLyLtROQEYDgwt9g27+OuBhCRpriqog1RjKmAjSEwxhgnaolAVXOAO4D5uFtbvq2qGSLymIgM9m02H9glImuBxcD9qrorWjH5s0RgjDFO1LqPAqjqPGBesWWP+v2twD2+R8youkRgg8mMMSb+jcVxsW8fHD4Mp5wS70iMMSb+PJkI8nugRqgDkjHGVGmeTAQ7d7pnSwTGGOPRRGBXBMYYU8iTiSD/isBuUWmMMR5NBHZFYIwxhTyZCHbuhBNPhLp14x2JMcbEnycTQXa2uxqw6SWMMcbDicDaB4wxxvFkIti509oHjDEmnycTgV0RGGNMIU8mArsiMMaYQp5LBEePurmGLBEYY4zjuUSwyzfJtVUNGWOM47lEYIPJjDGmqKjej6AysuklTHVx/PhxsrKyOHLkSLxDMZVI7dq1adWqFbVq1Qr7PZ5LBHZFYKqLrKws6tevT1JSEmKjIw2gquzatYusrCzatWsX9vs8VzVkVwSmujhy5AhNmjSxJGAKiAhNmjQp81Wi5xJBdrabWqJx43hHYkzFWRIwxZXnN+HJRNCoEdT0XKWYMcYE5rlEYIPJjFelpkJSEtSo4Z5TUyu2v/79+zN//vwiy5566inGjx8f9D39+vUjLS0NgCuuuII9e/aU2Gby5MlMmzYt5LHff/991q5dW/D60UcfZcGCBWUJP6QJEybQsmVL8vLyIrbPysxzicCmlzBelJoK48bBpk2g6p7HjatYMhgxYgSzZ88usmz27NmMGDEirPfPmzePk046qVzHLp4IHnvsMS699NJy7au4vLw85syZQ+vWrfn8888jss9AcnJyorbvsvJcIrArAuNFDz8Mhw4VXXbokFteXtdccw3//Oc/OXbsGACZmZls27aNPn36MH78eFJSUujSpQuTJk0K+P6kpCR2+npvTJkyhQ4dOtC7d2/Wr19fsM1LL71Ez549SU5OZujQoRw6dIjly5czd+5c7r//frp168aPP/7ImDFjePfddwFYuHAh3bt3p2vXrtx0000cPXq04HiTJk3inHPOoWvXrqxbty5gXJ999hldunRh/PjxzJo1q2D5zz//zFVXXUVycjLJycksX74cgBkzZnD22WeTnJzMDTfcAFAkHoB69eoV7LtPnz4MHjyYzp07A3DllVfSo0cPunTpwvTp0wve88knn3DOOeeQnJzMJZdcQl5eHu3btyfb1/UxLy+PM844o+B1hahqlXr06NFDK6J5c9WxYyu0C2MqhbVr14a9rYiquxYo+hCpWAwDBw7U999/X1VVp06dqvfee6+qqu7atUtVVXNycrRv3766Zs0aVVXt27evrlixQlVV27Ztq9nZ2ZqWlqZnnXWWHjx4UPfu3aunn366Pvnkk6qqunPnzoJjPfzww/rMM8+oquro0aP1nXfeKViX//rw4cPaqlUrXb9+vaqq3nDDDfrXv/614Hj573/uuef05ptvDviZbrnlFp0xY4bu3btXW7RooceOHVNV1euuu65gXzk5Obpnzx5NT0/X9u3ba3Z2dpHPXTy+unXrqqrq4sWLNTExUTds2FCwLv89hw4d0i5duujOnTt1x44d2qpVq4Lt8reZPHlyQQzz58/Xq6++OuBnCPTbANI0yHnVU1cEqu6KwKqGjNe0aVO25eHyrx7yrxZ6++23Oeecc+jevTsZGRlFqnGKW7p0KVdddRWJiYk0aNCAwYMHF6xLT0+nT58+dO3aldTUVDIyMkLGs379etq1a0eHDh0AGD16NEuWLClYf/XVVwPQo0cPMjMzS7z/2LFjzJs3jyuvvJIGDRpw3nnnFbSDLFq0qKD9IyEhgYYNG7Jo0SKuvfZamvpOKo3D6I547rnnFunj/8wzz5CcnMz555/Pli1b+P777/nyyy+56KKLCrbL3+9NN93EjBkzAHj11Ve58cYbSz1eODyVCPbsgdxcqxoy3jNlCiQmFl2WmOiWV8SQIUNYuHAhq1at4tChQ/To0YONGzcybdo0Fi5cyDfffMPAgQPLPfp5zJgxPPvss3z77bdMmjSpwqOoTzzxRMCdyAPV0c+fP589e/bQtWtXkpKSWLZsWZHqoXDVrFmzoKE5Ly+voPoMoK7fPXI/++wzFixYwBdffMGaNWvo3r17yM/YunVrmjdvzqJFi/j3v//N5ZdfXubYAvFUIrDBZMarRo6E6dOhbVs3jqZtW/d65MiK7bdevXr079+fm266qeBqYN++fdStW5eGDRvy888/8/HHH4fcx0UXXcT777/P4cOH2b9/Px9++GHBuv3793Pqqady/PhxUv1atuvXr8/+/ftL7Ktjx45kZmbyww8/ADBz5kz69u0b9ueZNWsWL7/8MpmZmWRmZrJx40Y+/fRTDh06xCWXXMILL7wAQG5uLnv37uXiiy/mnXfeYZdvNsvdu3cDrj1i5cqVAMydO5fjx48HPN7evXtp1KgRiYmJrFu3ji+//BKA888/nyVLlrBx48Yi+wW45ZZbGDVqFNdeey0JCQlhf7ZQPJUIbHoJ42UjR0JmJuTlueeKJoF8I0aMYM2aNQWJIDk5me7du9OpUyeuv/56evXqFfL955xzDsOGDSM5OZnLL7+cnj17Fqz74x//yHnnnUevXr3o1KlTwfLhw4fz5JNP0r17d3788ceC5bVr1+a1117j2muvpWvXrtSoUYPbbrstrM9x6NAhPvnkEwYOHFiwrG7duvTu3ZsPP/yQp59+msWLF9O1a1d69OjB2rVr6dKlCw8//DB9+/YlOTmZe+65B4CxY8fy+eefk5yczBdffFHkKsDfgAEDyMnJ4cwzz2TixImcf/75ADRr1ozp06dz9dVXk5yczLBhwwreM3jwYA4cOBCxaiEAcW0IVUdKSorm90Muq7lzYcgQWLECUlIiHJgxMfbdd99x5plnxjsME2NpaWncfffdLF26NOg2gX4bIrJSVQOe+Tw1vtauCIwxVdkTTzzBCy+8UKSaLBI8WTVkbQTGmKpo4sSJbNq0id69e0d0v55KBDt3Qp06EKS6zhhjPMlTiSA726qFjDGmOE8lAhtMZowxJUU1EYjIABFZLyI/iMjEAOvHiEi2iHzte9wSzXjsisAYY0qKWiIQkQTgOeByoDMwQkQ6B9j076razfd4OVrxgF0RGBNJu3btolu3bnTr1o1TTjmFli1bFrz2H0kbSFpaGnfeeWepx7jwwgsjFS7gvemlwxXN7qPnAj+o6gYAEZkNDAGCTzoSZXZFYEzkNGnShK+//hpw9xCoV68e9913X8H6nJwcaga5A1RKSgopYQzmyZ/hMxKKTy/dv3//iO3bX6jPXVlFM9qWwBa/11nAeQG2GyoiFwH/Ae5W1S3FNxCRccA4gDblnCXryBE4cMCuCEz1NGEC+M7JEdOtGzz1VNneM2bMGGrXrs3q1avp1asXw4cP56677uLIkSPUqVOH1157jY4dO/LZZ58xbdo0PvroIyZPnszmzZvZsGEDmzdvZsKECQVXC/Xq1ePAgQN89tlnTJ48maZNm5Kenk6PHj148803ERHmzZvHPffcQ926denVqxcbNmzgo48+KhFb/vTSw4YNY9asWQWJ4Oeff+a2225jw4YNALzwwgtceOGFzJgxg2nTpiEinH322cycOZMxY8YwaNAgrrnmmhLxPfLIIzRq1Ih169bxn//8hyuvvJItW7Zw5MgR7rrrLsaNGwe46aUfeughcnNzadq0KZ9++ikdO3Zk+fLlNGvWjLy8PDp06MAXX3xBsxiVXOOdtj4EZqnqURG5FXgDuLj4Rqo6HZgObmRxeQ6UP8+QXREYE11ZWVksX76chIQE9u3bx9KlS6lZsyYLFizgoYce4h//+EeJ96xbt47Fixezf/9+OnbsyPjx46lVq1aRbVavXk1GRgYtWrSgV69e/Otf/yIlJYVbb72VJUuW0K5du5A3xZk1axYjRoxgyJAhPPTQQxw/fpxatWpx55130rdvX+bMmUNubi4HDhwgIyODxx9/nOXLl9O0adMic/0Es2rVKtLT0wtmDH311Vdp3Lgxhw8fpmfPngwdOpS8vDzGjh1bEO/u3bupUaMGo0aNIjU1lQkTJrBgwQKSk5NjlgQguolgK9Da73Ur37ICqrrL7+XLwP9EKxibcM5UZ2UtuUeT/2Roe/fuZfTo0Xz//feISNDJ1wYOHMiJJ57IiSeeyMknn8zPP/9Mq1atimxz7rnnFizr1q0bmZmZ1KtXj9NOO63g5DtixIgiN3fJlz+99F/+8hfq169fML30oEGDWLRoUcHUzvnTS8+YMSMi00vPmTMHoGB66ezs7KDTSw8ZMoQJEyZEdHrpcEUzEawA2otIO1wCGA5c77+BiJyqqtt9LwcD30UrGJtewpjY8J9g7ZFHHqF///7MmTOHzMxM+vXrF/A9+dNDQ/AposPZJhj/6aXBTTBXp04dBg0aFPY+oHzTSycmJtKvX78yTS8d6SkkShO1XkOqmgPcAczHneDfVtUMEXlMRPLvPHGniGSIyBrgTmBMtOKxRGBM7O3du5eWLVsC8Prrr0d8/x07dmTDhg0FN5n5+9//HnA7r04vHa6ojiNQ1Xmq2kFVT1fVKb5lj6rqXN/fD6pqF1VNVtX+qhr4JqIRYFVDxsTe73//ex588EG6d+8elZu116lTh+eff54BAwbQo0cP6tevT8OGDYts4+XppcPlmWmoP/gAXn8d3n0XYpxsjYkKm4baOXDgAPXq1UNVuf3222nfvj133313vMMqs3Cmlw5XWaeh9swUE0OGwJw5lgSMqW5eeuklunXrRpcuXdi7dy+33nprvEMqsyeeeIKhQ4cyderUuBzfM1cExlQ3dkVggrErAmM8pKoV5Ez0lec3YYnAmCqqdu3a7Nq1y5KBKaCq7Nq1i9q1a5fpffEeWWyMKadWrVqRlZVFdn7faGNwBYTig/FKY4nAmCqqVq1aRUayGlNeVjVkjDEeZ4nAGGM8zhKBMcZ4XJUbRyAi2cCmMrylKbAzSuFURfZ9lGTfSVH2fRRVXb6PtqoacLa1KpcIykpE0oINovAi+z5Ksu+kKPs+ivLC92FVQ8YY43GWCIwxxuO8kAhK3q7I2+z7KMm+k6Ls+yiq2n8f1b6NwBhjTGheuCIwxhgTgiUCY4zxuGqbCERkgIisF5EfRGRivOOJBxFpLSKLRWSt797Qd/mWNxaRT0Xke99zo3jHGksikiAiq0XkI9/rdiLyle+38ncROSHeMcaKiJwkIu+KyDoR+U5ELrDfh9zt+/+SLiKzRKR2df+NVMtEICIJwHPA5UBnYISIdI5vVHGRA9yrqp2B84Hbfd/DRGChqrYHFvpee8ldwHd+r/8E/FVVzwB+AW6OS1Tx8TTwiap2ApJx34tnfx8i0hK4E0hR1bOABGA41fw3Ui0TAXAu8IOqblDVY8BsYEicY4o5Vd2uqqt8f+/H/Sdvifsu3vBt9gZwZXwijD0RaQUMBF72vRbgYuBd3yae+T5EpCFwEfAKgKoeU9U9ePj34VMTqCMiNYFEYDvV/DdSXRNBS2CL3+ss3zLPEpEkoDvwFdBcVbf7Vv0ENI9TWPHwFPB7IM/3ugmwR1VzfK+99FtpB2QDr/mqyl4Wkbp4+PehqluBacBmXALYC6ykmv9GqmsiMH5EpB7wD2CCqu7zX6eu/7An+hCLyCBgh6qujHcslURN4BzgBVXtDhykWDWQl34fAL72kCG4JNkCqAsMiGtQMVBdE8FWoLXf61a+ZZ4jIrVwSSBVVd/zLf5ZRE71rT8V2BGv+GKsFzBYRDJx1YUX4+rIT/JVA4C3fitZQJaqfuV7/S4uMXj19wFwKbBRVbNV9TjwHu53U61/I9U1EawA2vta+k/ANfbMjXNMMeer/34F+E5V/+K3ai4w2vf3aOCDWMcWD6r6oKq2UtUk3G9ikaqOBBYD1/g289L38ROwRUQ6+hZdAqzFo78Pn83A+SKS6Pv/k/+dVOvfSLUdWSwiV+DqgxOAV1V1SpxDijkR6Q0sBb6lsE78IVw7wdtAG9yU3tep6u64BBknItIPuE9VB4nIabgrhMbAamCUqh6NZ3yxIiLdcA3nJwAbgBtxBUTP/j5E5A/AMFyvu9XALbg2gWr7G6m2icAYY0x4qmvVkDHGmDBZIjDGGI+zRGCMMR5nicAYYzzOEoExxnicJQJjfEQkV0S+9ntEbLI1EUkSkfRI7c+YSKpZ+ibGeMZhVe0W7yCMiTW7IjCmFCKSKSL/IyLfisi/ReQM3/IkEVkkIt+IyEIRaeNb3lxE5ojIGt/jQt+uEkTkJd9c9/8nInV829/pu2fENyIyO04f03iYJQJjCtUpVjU0zG/dXlXtCjyLG7EO8DfgDVU9G0gFnvEtfwb4XFWTcXP3ZPiWtweeU9UuwB5gqG/5RKC7bz+3RevDGROMjSw2xkdEDqhqvQDLM4GLVXWDbxK/n1S1iYjsBE5V1eO+5dtVtamIZAOt/Kcg8E0D/qnvZi+IyANALVV9XEQ+AQ4A7wPvq+qBKH9UY4qwKwJjwqNB/i4L/7lpcilsoxuIu6PeOcAKv1kujYkJSwTGhGeY3/MXvr+X42YxBRiJm+AP3O0dx0PB/ZEbBtupiNQAWqvqYuABoCFQ4qrEmGiykocxheqIyNd+rz9R1fwupI1E5BtcqX6Eb9nvcHf3uh93p68bfcvvAqaLyM24kv943N2uAkkA3vQlCwGe8d0u0piYsTYCY0rhayNIUdWd8Y7FmGiwqiFjjPE4uyIwxhiPsysCY4zxOEsExhjjcZYIjDHG4ywRGGOMx1kiMMYYj/v/wruKVmlcic8AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BjRl3WP_6j6A"
      },
      "source": [
        "**Rebuilding the best fit Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fjRAT2jrbDHA"
      },
      "source": [
        "model=models.Sequential()\n",
        "model.add(layers.Dense(16,kernel_regularizer=regularizers.l1_l2(l1=.002, l2=0.004) , activation=\"relu\", input_shape=(train_data.shape[1],)))\n",
        "model.add(layers.Dropout(.5))\n",
        "model.add(layers.Dense(16, kernel_regularizer=regularizers.l1_l2(l1=.002, l2=0.004), activation = \"relu\" ))\n",
        "model.add(layers.Dropout(.3))\n",
        "model.add(layers.Dense(1, activation=\"sigmoid\"))\n",
        "\n",
        "model.compile(optimizer=\"rmsprop\", loss = \"binary_crossentropy\", metrics=[\"accuracy\"])"
      ],
      "execution_count": 432,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ueZnXmec6wn_"
      },
      "source": [
        "**Training the model with all samples**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KAmbT8wk6xlO",
        "outputId": "32439a53-10bf-43b3-cad9-e4eeb75ac4c0"
      },
      "source": [
        "model.fit(train_data, train_labels, epochs=90, batch_size=4)"
      ],
      "execution_count": 433,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/90\n",
            "53/53 [==============================] - 1s 1ms/step - loss: 1.3465 - accuracy: 0.4438\n",
            "Epoch 2/90\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 1.1081 - accuracy: 0.6240\n",
            "Epoch 3/90\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 1.1081 - accuracy: 0.6013\n",
            "Epoch 4/90\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.9903 - accuracy: 0.6882\n",
            "Epoch 5/90\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 1.0409 - accuracy: 0.6766\n",
            "Epoch 6/90\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 1.0148 - accuracy: 0.7004\n",
            "Epoch 7/90\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 1.0340 - accuracy: 0.6747\n",
            "Epoch 8/90\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.9278 - accuracy: 0.7132\n",
            "Epoch 9/90\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.9103 - accuracy: 0.7364\n",
            "Epoch 10/90\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.8394 - accuracy: 0.7880\n",
            "Epoch 11/90\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.7871 - accuracy: 0.8449\n",
            "Epoch 12/90\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.8072 - accuracy: 0.7848\n",
            "Epoch 13/90\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.8150 - accuracy: 0.7843\n",
            "Epoch 14/90\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.7705 - accuracy: 0.7915\n",
            "Epoch 15/90\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.7299 - accuracy: 0.8292\n",
            "Epoch 16/90\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.7407 - accuracy: 0.8324\n",
            "Epoch 17/90\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.6587 - accuracy: 0.8663\n",
            "Epoch 18/90\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.7394 - accuracy: 0.8200\n",
            "Epoch 19/90\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.6398 - accuracy: 0.8397\n",
            "Epoch 20/90\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.6483 - accuracy: 0.8261\n",
            "Epoch 21/90\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.6252 - accuracy: 0.8567\n",
            "Epoch 22/90\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.5589 - accuracy: 0.8549\n",
            "Epoch 23/90\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.6050 - accuracy: 0.8106\n",
            "Epoch 24/90\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.5277 - accuracy: 0.8906\n",
            "Epoch 25/90\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.6678 - accuracy: 0.8280\n",
            "Epoch 26/90\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.6188 - accuracy: 0.8616\n",
            "Epoch 27/90\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.5553 - accuracy: 0.8766\n",
            "Epoch 28/90\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.5406 - accuracy: 0.8360\n",
            "Epoch 29/90\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.5610 - accuracy: 0.8717\n",
            "Epoch 30/90\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.4766 - accuracy: 0.8932\n",
            "Epoch 31/90\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.5480 - accuracy: 0.8566\n",
            "Epoch 32/90\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.5023 - accuracy: 0.8961\n",
            "Epoch 33/90\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.4789 - accuracy: 0.8927\n",
            "Epoch 34/90\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.4836 - accuracy: 0.8893\n",
            "Epoch 35/90\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.4716 - accuracy: 0.9039\n",
            "Epoch 36/90\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.4624 - accuracy: 0.8584\n",
            "Epoch 37/90\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.4736 - accuracy: 0.9103\n",
            "Epoch 38/90\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.4274 - accuracy: 0.9036\n",
            "Epoch 39/90\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.4592 - accuracy: 0.9263\n",
            "Epoch 40/90\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.4339 - accuracy: 0.8791\n",
            "Epoch 41/90\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.5096 - accuracy: 0.8605\n",
            "Epoch 42/90\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.4520 - accuracy: 0.9012\n",
            "Epoch 43/90\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.4894 - accuracy: 0.8612\n",
            "Epoch 44/90\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.3962 - accuracy: 0.9117\n",
            "Epoch 45/90\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.4378 - accuracy: 0.9109\n",
            "Epoch 46/90\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.3812 - accuracy: 0.9328\n",
            "Epoch 47/90\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.3743 - accuracy: 0.9298\n",
            "Epoch 48/90\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.4192 - accuracy: 0.9190\n",
            "Epoch 49/90\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.5291 - accuracy: 0.8391\n",
            "Epoch 50/90\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.3662 - accuracy: 0.9185\n",
            "Epoch 51/90\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.3466 - accuracy: 0.9403\n",
            "Epoch 52/90\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.3678 - accuracy: 0.9199\n",
            "Epoch 53/90\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.3560 - accuracy: 0.9380\n",
            "Epoch 54/90\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.3530 - accuracy: 0.9359\n",
            "Epoch 55/90\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.3735 - accuracy: 0.9199\n",
            "Epoch 56/90\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.3471 - accuracy: 0.9336\n",
            "Epoch 57/90\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.3943 - accuracy: 0.8968\n",
            "Epoch 58/90\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.3898 - accuracy: 0.9135\n",
            "Epoch 59/90\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.4238 - accuracy: 0.8850\n",
            "Epoch 60/90\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.3261 - accuracy: 0.9324\n",
            "Epoch 61/90\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.3173 - accuracy: 0.9385\n",
            "Epoch 62/90\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.3701 - accuracy: 0.9223\n",
            "Epoch 63/90\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.3682 - accuracy: 0.9187\n",
            "Epoch 64/90\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.3296 - accuracy: 0.9359\n",
            "Epoch 65/90\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.3734 - accuracy: 0.9053\n",
            "Epoch 66/90\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.4461 - accuracy: 0.8583\n",
            "Epoch 67/90\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.3132 - accuracy: 0.9410\n",
            "Epoch 68/90\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.3765 - accuracy: 0.8949\n",
            "Epoch 69/90\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.3175 - accuracy: 0.9507\n",
            "Epoch 70/90\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.3223 - accuracy: 0.9312\n",
            "Epoch 71/90\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.3170 - accuracy: 0.9395\n",
            "Epoch 72/90\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.3763 - accuracy: 0.8985\n",
            "Epoch 73/90\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.2992 - accuracy: 0.9241\n",
            "Epoch 74/90\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.3196 - accuracy: 0.9259\n",
            "Epoch 75/90\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.2931 - accuracy: 0.9398\n",
            "Epoch 76/90\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.3227 - accuracy: 0.9371\n",
            "Epoch 77/90\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.3599 - accuracy: 0.9090\n",
            "Epoch 78/90\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.2840 - accuracy: 0.9453\n",
            "Epoch 79/90\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.3678 - accuracy: 0.9191\n",
            "Epoch 80/90\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.2710 - accuracy: 0.9572\n",
            "Epoch 81/90\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.3480 - accuracy: 0.8979\n",
            "Epoch 82/90\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.3420 - accuracy: 0.8966\n",
            "Epoch 83/90\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.2848 - accuracy: 0.9506\n",
            "Epoch 84/90\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.2693 - accuracy: 0.9598\n",
            "Epoch 85/90\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.3084 - accuracy: 0.9507\n",
            "Epoch 86/90\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.3157 - accuracy: 0.9377\n",
            "Epoch 87/90\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.3066 - accuracy: 0.9463\n",
            "Epoch 88/90\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.3247 - accuracy: 0.9239\n",
            "Epoch 89/90\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.3430 - accuracy: 0.9203\n",
            "Epoch 90/90\n",
            "53/53 [==============================] - 0s 1ms/step - loss: 0.2798 - accuracy: 0.9525\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f9b8961ad50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 433
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pgv4TrCd7KbY"
      },
      "source": [
        "**Evaluating the Network**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ORGrBwIqAvH",
        "outputId": "532de9d6-7bba-4742-d025-0b8a73abe7d5"
      },
      "source": [
        "test_loss_score, test_acc_score=model.evaluate(test_data, test_labels)"
      ],
      "execution_count": 434,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 0s 2ms/step - loss: 0.2960 - accuracy: 0.9286\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZrXFKWctqI9W",
        "outputId": "4c8b412a-f743-4909-ccb5-8059369186a3"
      },
      "source": [
        "test_acc_score *100"
      ],
      "execution_count": 435,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "92.85714030265808"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 435
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hWKkYGTDgmB_"
      },
      "source": [
        "**Predicting the Network**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7IPuJNW3qOuc"
      },
      "source": [
        "prediction=model.predict(test_data)\n",
        "pred_norm =np.where(prediction>.5, 1, 0)\n",
        "pred_norm=np.where(pred_norm==1, \"g\", \"b\")"
      ],
      "execution_count": 436,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S9zzbx5otb-D",
        "outputId": "bcae9219-d7a4-4c02-cdbe-303d50869f8a"
      },
      "source": [
        "pred_norm = pred_norm.reshape(pred_norm.shape[0],)\n",
        "pred_norm[:10].T"
      ],
      "execution_count": 437,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['g', 'b', 'b', 'g', 'g', 'g', 'g', 'b', 'g', 'g'], dtype='<U1')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 437
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MV2IDjO7qYAg"
      },
      "source": [
        "test_labels_new = np.where(test_labels==1, \"g\", \"b\")"
      ],
      "execution_count": 438,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4-SiadIbrLZJ",
        "outputId": "eb35533e-69e7-4577-f254-2ae53c8c4ace"
      },
      "source": [
        "test_labels_new[:10].T"
      ],
      "execution_count": 439,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['g', 'b', 'b', 'g', 'g', 'g', 'g', 'g', 'g', 'g'], dtype='<U1')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 439
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z3hSnJH4r7SZ",
        "outputId": "c52fc814-d88c-4949-ac15-8fba909c9000"
      },
      "source": [
        "c= pred_norm.size\n",
        "c"
      ],
      "execution_count": 440,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "140"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 440
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3TmheyUKulmv"
      },
      "source": [
        "comapre_pred_test = test_labels_new == pred_norm"
      ],
      "execution_count": 441,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zh8aKiQTsgCh",
        "outputId": "3ceba20e-8978-4fa0-efe2-3b18c4694505"
      },
      "source": [
        "b = comapre_pred_test[comapre_pred_test[:]==True].size\n",
        "b"
      ],
      "execution_count": 442,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "130"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 442
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O2oCJ2_xtQBn",
        "outputId": "7af0c737-b688-4376-e973-7216208e66aa"
      },
      "source": [
        "a = comapre_pred_test[comapre_pred_test[:]==False].size\n",
        "a"
      ],
      "execution_count": 443,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 443
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QoVZIRgytUR1",
        "outputId": "63d7da7b-bcb8-4893-c60d-96bc400fbeff"
      },
      "source": [
        "print(\"Incorrect Predictions are:\", a, \"and Correct predictions are :\", b, \" the percentage is:\", round((b/c)*100,2), \"%\"  )"
      ],
      "execution_count": 444,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Incorrect Predictions are: 10 and Correct predictions are : 130  the percentage is: 92.86 %\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}